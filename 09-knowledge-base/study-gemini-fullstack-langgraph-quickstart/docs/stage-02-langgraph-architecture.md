# é˜¶æ®µ 2: LangGraph å›¾ç»“æ„ - æ ¸å¿ƒé€»è¾‘

## ğŸ“š å­¦ä¹ ç›®æ ‡

- ç†è§£ LangGraph çš„å·¥ä½œåŸç†
- æŒæ¡èŠ‚ç‚¹ã€è¾¹ã€æ¡ä»¶è·¯ç”±çš„æ¦‚å¿µ
- ç†è§£å¹¶è¡Œæ‰§è¡Œå’Œ Send æœºåˆ¶
- æ·±å…¥ç†è§£æ¯ä¸ªèŠ‚ç‚¹çš„å®ç°
- æŒæ¡çŠ¶æ€è½¬æ¢æµç¨‹

---

## ğŸ¯ LangGraph æ ¸å¿ƒæ¦‚å¿µ

### å›¾ (Graph) çš„æ„æˆ

LangGraph ä½¿ç”¨**æœ‰å‘å›¾**æ¥ç¼–æ’ AI Agent çš„å·¥ä½œæµç¨‹:

```
èŠ‚ç‚¹ (Node) â†’ æ‰§è¡Œä»»åŠ¡çš„å‡½æ•°
è¾¹ (Edge) â†’ è¿æ¥èŠ‚ç‚¹çš„è·¯å¾„
çŠ¶æ€ (State) â†’ åœ¨èŠ‚ç‚¹é—´æµåŠ¨çš„æ•°æ®
```

### StateGraph ç±»

**æ–‡ä»¶ä½ç½®**: `backend/src/agent/graph.py:269`

```python
builder = StateGraph(OverallState, config_schema=Configuration)
```

**å‚æ•°è¯´æ˜**:
- `OverallState`: å›¾çš„çŠ¶æ€ç±»å‹,å®šä¹‰èŠ‚ç‚¹é—´ä¼ é€’çš„æ•°æ®ç»“æ„
- `config_schema`: é…ç½®ç±»å‹,ç”¨äºä»ç¯å¢ƒå˜é‡æˆ– RunnableConfig åŠ è½½é…ç½®

---

## ğŸ“Š å®Œæ•´å›¾ç»“æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        START                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  generate_query                             â”‚
â”‚  ä½¿ç”¨ Gemini 2.0 Flash ç”Ÿæˆåˆå§‹æœç´¢æŸ¥è¯¢                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              continue_to_web_research                       â”‚
â”‚     æ¡ä»¶è¾¹: ä¸ºæ¯ä¸ªæŸ¥è¯¢åˆ›å»ºå¹¶è¡Œåˆ†æ”¯ (ä½¿ç”¨ Send)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â–¼               â–¼               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   web_   â”‚    â”‚   web_   â”‚    â”‚   web_   â”‚
    â”‚ research â”‚    â”‚ research â”‚    â”‚ research â”‚
    â”‚  (æŸ¥è¯¢1) â”‚    â”‚  (æŸ¥è¯¢2) â”‚    â”‚  (æŸ¥è¯¢3) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚               â”‚               â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     reflection                              â”‚
â”‚  åˆ†ææœç´¢ç»“æœ,è¯†åˆ«çŸ¥è¯†ç¼ºå£,ç”Ÿæˆåç»­æŸ¥è¯¢                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 evaluate_research                           â”‚
â”‚  æ¡ä»¶è·¯ç”±: åˆ¤æ–­ç ”ç©¶æ˜¯å¦å……åˆ†æˆ–è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                            â”‚
            ç ”ç©¶ä¸å……åˆ†                       ç ”ç©¶å……åˆ†
            ä¸”æœªè¾¾æœ€å¤§å¾ªç¯                     æˆ–è¾¾æœ€å¤§å¾ªç¯
                    â”‚                            â”‚
                    â–¼                            â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  web_research    â”‚        â”‚  finalize_answer    â”‚
         â”‚  (åç»­æŸ¥è¯¢)       â”‚        â”‚  ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚
                                             â–¼
                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                     â”‚      END      â”‚
                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ èŠ‚ç‚¹è¯¦è§£

### 1. generate_query èŠ‚ç‚¹

**æ–‡ä»¶ä½ç½®**: `backend/src/agent/graph.py:44-81`

#### åŠŸèƒ½
æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ç”Ÿæˆä¼˜åŒ–çš„æœç´¢æŸ¥è¯¢

#### å®ç°ç»†èŠ‚

```python
def generate_query(state: OverallState, config: RunnableConfig) -> QueryGenerationState:
    configurable = Configuration.from_runnable_config(config)

    # æ£€æŸ¥å¹¶è®¾ç½®åˆå§‹æŸ¥è¯¢æ•°é‡
    if state.get("initial_search_query_count") is None:
        state["initial_search_query_count"] = configurable.number_of_initial_queries

    # åˆå§‹åŒ– Gemini 2.0 Flash
    llm = ChatGoogleGenerativeAI(
        model=configurable.query_generator_model,  # gemini-2.0-flash
        temperature=1.0,  # é«˜æ¸©åº¦ä»¥å¢åŠ å¤šæ ·æ€§
        max_retries=2,
        api_key=os.getenv("GEMINI_API_KEY"),
    )
    structured_llm = llm.with_structured_output(SearchQueryList)

    # æ ¼å¼åŒ–æç¤ºè¯
    formatted_prompt = query_writer_instructions.format(
        current_date=get_current_date(),
        research_topic=get_research_topic(state["messages"]),
        number_queries=state["initial_search_query_count"],
    )

    # ç”Ÿæˆæœç´¢æŸ¥è¯¢
    result = structured_llm.invoke(formatted_prompt)
    return {"search_query": result.query}
```

#### å…³é”®ç‚¹

| å…ƒç´  | å€¼ | è¯´æ˜ |
|------|-----|------|
| è¾“å…¥çŠ¶æ€ | `OverallState` | åŒ…å«ç”¨æˆ·æ¶ˆæ¯ |
| è¾“å‡ºçŠ¶æ€ | `QueryGenerationState` | è¿”å› search_query |
| æ¨¡å‹ | `gemini-2.0-flash` | å¿«é€Ÿç”Ÿæˆ,é€‚åˆæŸ¥è¯¢ç”Ÿæˆ |
| Temperature | `1.0` | é«˜æ¸©åº¦å¢åŠ æŸ¥è¯¢å¤šæ ·æ€§ |
| ç»“æ„åŒ–è¾“å‡º | `SearchQueryList` | ç¡®ä¿è¾“å‡ºæ ¼å¼æ­£ç¡® |

#### æç¤ºè¯åˆ†æ

**query_writer_instructions** (prompts.py:9-34):

```
- ä¼˜å…ˆä½¿ç”¨å•ä¸€æŸ¥è¯¢
- æ¯ä¸ªæŸ¥è¯¢å…³æ³¨ä¸€ä¸ªç‰¹å®šæ–¹é¢
- æœ€å¤šç”Ÿæˆ number_queries ä¸ªæŸ¥è¯¢
- æŸ¥è¯¢åº”è¯¥å¤šæ ·åŒ–
- ä¸è¦ç”Ÿæˆç›¸ä¼¼çš„æŸ¥è¯¢
- ç¡®ä¿è·å–æœ€æ–°ä¿¡æ¯
```

#### è¾“å‡ºç¤ºä¾‹

```json
{
  "query": [
    "renewable energy trends 2024",
    "solar energy advancements 2024",
    "wind energy technology 2024"
  ],
  "rationale": "These queries cover recent developments in different renewable energy sectors."
}
```

---

### 2. continue_to_web_research å‡½æ•°

**æ–‡ä»¶ä½ç½®**: `backend/src/agent/graph.py:84-92`

#### åŠŸèƒ½
å°†æŸ¥è¯¢åˆ†å‘åˆ°å¤šä¸ªå¹¶è¡Œçš„ web_research èŠ‚ç‚¹

#### å®ç°ç»†èŠ‚

```python
def continue_to_web_research(state: QueryGenerationState):
    """ä¸ºæ¯ä¸ªæœç´¢æŸ¥è¯¢åˆ›å»ºä¸€ä¸ª web_research ä»»åŠ¡"""
    return [
        Send("web_research", {"search_query": search_query, "id": int(idx)})
        for idx, search_query in enumerate(state["search_query"])
    ]
```

#### Send å¯¹è±¡è¯¦è§£

`Send` æ˜¯ LangGraph ä¸­å®ç°**å¹¶è¡Œæ‰§è¡Œ**çš„å…³é”®æœºåˆ¶:

```python
Send("ç›®æ ‡èŠ‚ç‚¹", {çŠ¶æ€æ›´æ–°})
```

**å‚æ•°è¯´æ˜**:
- ç¬¬ä¸€ä¸ªå‚æ•°: ç›®æ ‡èŠ‚ç‚¹åç§°
- ç¬¬äºŒä¸ªå‚æ•°: ä¼ é€’ç»™è¯¥èŠ‚ç‚¹çš„çŠ¶æ€æ›´æ–°

#### å¹¶è¡Œæ‰§è¡Œç¤ºä¾‹

å‡è®¾ç”Ÿæˆäº† 3 ä¸ªæŸ¥è¯¢:

```python
state["search_query"] = [
    "renewable energy trends 2024",
    "solar energy advancements",
    "wind energy technology"
]
```

`continue_to_web_research` è¿”å›:

```python
[
    Send("web_research", {"search_query": "renewable energy trends 2024", "id": 0}),
    Send("web_research", {"search_query": "solar energy advancements", "id": 1}),
    Send("web_research", {"search_query": "wind energy technology", "id": 2})
]
```

LangGraph ä¼šåˆ›å»º **3 ä¸ªå¹¶è¡Œä»»åŠ¡**,æ¯ä¸ªä»»åŠ¡ç‹¬ç«‹æ‰§è¡Œ `web_research` èŠ‚ç‚¹ã€‚

#### ä¸ºä»€ä¹ˆéœ€è¦ continue_to_web_research?

âœ… **å•ä¸€èŒè´£åŸåˆ™**: `generate_query` åªè´Ÿè´£ç”ŸæˆæŸ¥è¯¢,ä¸è´Ÿè´£åˆ†å‘
âœ… **å¹¶è¡Œä¼˜åŒ–**: å¤šä¸ªæŸ¥è¯¢å¯ä»¥åŒæ—¶æ‰§è¡Œ,æé«˜æ•ˆç‡
âœ… **çŠ¶æ€éš”ç¦»**: æ¯ä¸ªæœç´¢ä»»åŠ¡æœ‰è‡ªå·±çš„ ID,ä¾¿äºè¿½è¸ª

---

### 3. web_research èŠ‚ç‚¹

**æ–‡ä»¶ä½ç½®**: `backend/src/agent/graph.py:95-136`

#### åŠŸèƒ½
ä½¿ç”¨ Google Search API æ‰§è¡Œç½‘ç»œæœç´¢å¹¶ç”Ÿæˆæ‘˜è¦

#### å®ç°ç»†èŠ‚

```python
def web_research(state: WebSearchState, config: RunnableConfig) -> OverallState:
    configurable = Configuration.from_runnable_config(config)

    # æ ¼å¼åŒ–æç¤ºè¯
    formatted_prompt = web_searcher_instructions.format(
        current_date=get_current_date(),
        research_topic=state["search_query"],
    )

    # ä½¿ç”¨ Google GenAI Client (é LangChain wrapper)
    # å› ä¸º LangChain å®¢æˆ·ç«¯ä¸è¿”å› grounding_metadata
    response = genai_client.models.generate_content(
        model=configurable.query_generator_model,
        contents=formatted_prompt,
        config={
            "tools": [{"google_search": {}}],  # å¯ç”¨ Google Search
            "temperature": 0,
        },
    )

    # è§£æ URL ä¸ºçŸ­ URL (èŠ‚çœ token)
    resolved_urls = resolve_urls(
        response.candidates[0].grounding_metadata.grounding_chunks,
        state["id"]
    )

    # æå–å¼•ç”¨å¹¶æ’å…¥åˆ°æ–‡æœ¬ä¸­
    citations = get_citations(response, resolved_urls)
    modified_text = insert_citation_markers(response.text, citations)
    sources_gathered = [item for citation in citations for item in citation["segments"]]

    return {
        "sources_gathered": sources_gathered,
        "search_query": [state["search_query"]],
        "web_research_result": [modified_text],
    }
```

#### å…³é”®ç‚¹

| å…ƒç´  | å€¼ | è¯´æ˜ |
|------|-----|------|
| è¾“å…¥çŠ¶æ€ | `WebSearchState` | å•ä¸ªæŸ¥è¯¢å’Œ ID |
| è¾“å‡ºçŠ¶æ€ | `OverallState` | ç´¯ç§¯æœç´¢ç»“æœå’Œæ¥æº |
| API | Google GenAI Client | åŸç”Ÿå®¢æˆ·ç«¯,æ”¯æŒ grounding |
| Tools | `google_search` | å¯ç”¨ Google æœç´¢ |
| Temperature | `0` | ä½æ¸©åº¦,ç¡®ä¿å‡†ç¡®æ€§ |

#### ä¸ºä»€ä¹ˆä½¿ç”¨åŸç”Ÿ Google GenAI Client?

```python
# âŒ LangChain å®¢æˆ·ç«¯
llm = ChatGoogleGenerativeAI(...)
response = llm.invoke(...)  # ä¸è¿”å› grounding_metadata

# âœ… åŸç”Ÿå®¢æˆ·ç«¯
from google.genai import Client
client = Client(...)
response = client.models.generate_content(...)  # è¿”å› grounding_metadata
```

`grounding_metadata` åŒ…å«:
- `grounding_chunks`: æœç´¢ç»“æœçš„è¯¦ç»†ä¿¡æ¯
- `grounding_supports`: å¼•ç”¨çš„ä½ç½®å’Œç´¢å¼•
- è¿™äº›ä¿¡æ¯ç”¨äºç”Ÿæˆå¸¦å¼•ç”¨çš„ç­”æ¡ˆ

#### å¼•ç”¨å¤„ç†æµç¨‹

```
Google Search API
    â†“
grounding_metadata
    â”œâ”€ grounding_chunks (æ¥æºä¿¡æ¯)
    â””â”€ grounding_supports (å¼•ç”¨ä½ç½®)
    â†“
resolve_urls (è½¬æ¢ä¸ºçŸ­ URL)
    â†“
get_citations (æå–å¼•ç”¨å¯¹è±¡)
    â†“
insert_citation_markers (æ’å…¥å¼•ç”¨æ ‡è®°)
    â†“
æœ€ç»ˆæ–‡æœ¬ (å¸¦å¼•ç”¨çš„ Markdown)
```

#### è¾“å‡ºç¤ºä¾‹

```markdown
Renewable energy saw significant growth in 2024 [1](https://vertexaisearch.cloud.google.com/id/0-0).
Solar capacity increased by 25% compared to 2023 [2](https://vertexaisearch.cloud.google.com/id/0-1).
```

---

### 4. reflection èŠ‚ç‚¹

**æ–‡ä»¶ä½ç½®**: `backend/src/agent/graph.py:139-180`

#### åŠŸèƒ½
åˆ†ææœç´¢ç»“æœ,è¯†åˆ«çŸ¥è¯†ç¼ºå£,ç”Ÿæˆåç»­æŸ¥è¯¢

#### å®ç°ç»†èŠ‚

```python
def reflection(state: OverallState, config: RunnableConfig) -> ReflectionState:
    configurable = Configuration.from_runnable_config(config)

    # å¢åŠ ç ”ç©¶å¾ªç¯è®¡æ•°
    state["research_loop_count"] = state.get("research_loop_count", 0) + 1
    reasoning_model = state.get("reasoning_model", configurable.reflection_model)

    # æ ¼å¼åŒ–æç¤ºè¯
    formatted_prompt = reflection_instructions.format(
        current_date=get_current_date(),
        research_topic=get_research_topic(state["messages"]),
        summaries="\n\n---\n\n".join(state["web_research_result"]),  # æ‰€æœ‰æœç´¢ç»“æœ
    )

    # åˆå§‹åŒ–æ¨ç†æ¨¡å‹
    llm = ChatGoogleGenerativeAI(
        model=reasoning_model,  # gemini-2.5-flash
        temperature=1.0,
        max_retries=2,
        api_key=os.getenv("GEMINI_API_KEY"),
    )
    result = llm.with_structured_output(Reflection).invoke(formatted_prompt)

    return {
        "is_sufficient": result.is_sufficient,
        "knowledge_gap": result.knowledge_gap,
        "follow_up_queries": result.follow_up_queries,
        "research_loop_count": state["research_loop_count"],
        "number_of_ran_queries": len(state["search_query"]),
    }
```

#### å…³é”®ç‚¹

| å…ƒç´  | å€¼ | è¯´æ˜ |
|------|-----|------|
| è¾“å…¥çŠ¶æ€ | `OverallState` | åŒ…å«æ‰€æœ‰æœç´¢ç»“æœ |
| è¾“å‡ºçŠ¶æ€ | `ReflectionState` | åæ€ç»“æœå’Œåç»­æŸ¥è¯¢ |
| æ¨¡å‹ | `gemini-2.5-flash` | æ›´å¼ºçš„æ¨ç†èƒ½åŠ› |
| Temperature | `1.0` | é¼“åŠ±æ¢ç´¢æ€§æŸ¥è¯¢ |

#### æç¤ºè¯åˆ†æ

**reflection_instructions** (prompts.py:50-80):

```
- è¯†åˆ«çŸ¥è¯†ç¼ºå£æˆ–éœ€è¦æ·±å…¥æ¢ç´¢çš„é¢†åŸŸ
- å¦‚æœæ‘˜è¦å……åˆ†,ä¸ç”Ÿæˆåç»­æŸ¥è¯¢
- å¦‚æœæœ‰çŸ¥è¯†ç¼ºå£,ç”Ÿæˆåç»­æŸ¥è¯¢
- å…³æ³¨æŠ€æœ¯ç»†èŠ‚ã€å®ç°ç»†èŠ‚æˆ–æœªå®Œå…¨è¦†ç›–çš„æ–°å…´è¶‹åŠ¿
- è¾“å‡º JSON æ ¼å¼
```

#### è¾“å‡ºç¤ºä¾‹

**ç ”ç©¶ä¸å……åˆ†æ—¶**:
```json
{
  "is_sufficient": false,
  "knowledge_gap": "Missing information about cost trends and policy changes in renewable energy sector",
  "follow_up_queries": [
    "renewable energy cost trends 2024",
    "energy policy changes 2024"
  ]
}
```

**ç ”ç©¶å……åˆ†æ—¶**:
```json
{
  "is_sufficient": true,
  "knowledge_gap": "",
  "follow_up_queries": []
}
```

---

### 5. evaluate_research è·¯ç”±å‡½æ•°

**æ–‡ä»¶ä½ç½®**: `backend/src/agent/graph.py:183-217`

#### åŠŸèƒ½
æ¡ä»¶è·¯ç”±: å†³å®šæ˜¯ç»§ç»­ç ”ç©¶è¿˜æ˜¯ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ

#### å®ç°ç»†èŠ‚

```python
def evaluate_research(state: ReflectionState, config: RunnableConfig) -> OverallState:
    configurable = Configuration.from_runnable_config(config)
    max_research_loops = (
        state.get("max_research_loops")
        if state.get("max_research_loops") is not None
        else configurable.max_research_loops
    )

    # åˆ¤æ–­æ˜¯å¦åº”è¯¥ç»“æŸ
    if state["is_sufficient"] or state["research_loop_count"] >= max_research_loops:
        return "finalize_answer"
    else:
        # ä¸ºæ¯ä¸ªåç»­æŸ¥è¯¢åˆ›å»ºå¹¶è¡Œä»»åŠ¡
        return [
            Send(
                "web_research",
                {
                    "search_query": follow_up_query,
                    "id": state["number_of_ran_queries"] + int(idx),
                },
            )
            for idx, follow_up_query in enumerate(state["follow_up_queries"])
        ]
```

#### å†³ç­–é€»è¾‘

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  is_sufficient == True?             â”‚ â†’ Yes â†’ finalize_answer
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ No
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  research_loop_count >= max_loops?  â”‚ â†’ Yes â†’ finalize_answer
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ No
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç»§ç»­ç ”ç©¶ (ç”Ÿæˆå¹¶è¡Œ web_research)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ç»ˆæ­¢æ¡ä»¶

1. **ç ”ç©¶å……åˆ†**: `is_sufficient == True`
2. **è¾¾åˆ°æœ€å¤§å¾ªç¯**: `research_loop_count >= max_research_loops`

#### ç»§ç»­ç ”ç©¶çš„é€»è¾‘

ç”Ÿæˆåç»­æŸ¥è¯¢çš„å¹¶è¡Œä»»åŠ¡:

```python
# å‡è®¾ follow_up_queries = ["cost trends", "policy changes"]
# number_of_ran_queries = 3 (ä¹‹å‰çš„ 3 ä¸ªæŸ¥è¯¢)

[
    Send("web_research", {"search_query": "cost trends", "id": 3}),
    Send("web_research", {"search_query": "policy changes", "id": 4})
]
```

---

### 6. finalize_answer èŠ‚ç‚¹

**æ–‡ä»¶ä½ç½®**: `backend/src/agent/graph.py:220-265`

#### åŠŸèƒ½
åŸºäºæ‰€æœ‰æ”¶é›†çš„ä¿¡æ¯ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ

#### å®ç°ç»†èŠ‚

```python
def finalize_answer(state: OverallState, config: RunnableConfig):
    configurable = Configuration.from_runnable_config(config)
    reasoning_model = state.get("reasoning_model") or configurable.answer_model

    # æ ¼å¼åŒ–æç¤ºè¯
    formatted_prompt = answer_instructions.format(
        current_date=get_current_date(),
        research_topic=get_research_topic(state["messages"]),
        summaries="\n---\n\n".join(state["web_research_result"]),
    )

    # åˆå§‹åŒ–æ¨ç†æ¨¡å‹ (Gemini 2.5 Pro)
    llm = ChatGoogleGenerativeAI(
        model=reasoning_model,  # gemini-2.5-pro
        temperature=0,  # ä½æ¸©åº¦,ç¡®ä¿å‡†ç¡®æ€§
        max_retries=2,
        api_key=os.getenv("GEMINI_API_KEY"),
    )
    result = llm.invoke(formatted_prompt)

    # æ›¿æ¢çŸ­ URL ä¸ºåŸå§‹ URL
    unique_sources = []
    for source in state["sources_gathered"]:
        if source["short_url"] in result.content:
            result.content = result.content.replace(
                source["short_url"], source["value"]
            )
            unique_sources.append(source)

    return {
        "messages": [AIMessage(content=result.content)],
        "sources_gathered": unique_sources,
    }
```

#### å…³é”®ç‚¹

| å…ƒç´  | å€¼ | è¯´æ˜ |
|------|-----|------|
| è¾“å…¥çŠ¶æ€ | `OverallState` | æ‰€æœ‰æœç´¢ç»“æœå’Œæ¥æº |
| è¾“å‡ºçŠ¶æ€ | `OverallState` | æœ€ç»ˆç­”æ¡ˆæ¶ˆæ¯ |
| æ¨¡å‹ | `gemini-2.5-pro` | æœ€å¼ºçš„æ¨ç†èƒ½åŠ› |
| Temperature | `0` | ä½æ¸©åº¦,ç¡®ä¿å‡†ç¡®æ€§ |

#### URL æ›¿æ¢é€»è¾‘

```python
# æ‘˜è¦ä¸­çš„çŸ­ URL
"Renewable energy grew [1](https://vertexaisearch.cloud.google.com/id/0-0)"

# æ›¿æ¢ä¸ºåŸå§‹ URL
"Renewable energy grew [1](https://www.example.com/renewable-energy-2024)"
```

---

## ğŸ”¨ å›¾æ„å»ºæµç¨‹

**æ–‡ä»¶ä½ç½®**: `backend/src/agent/graph.py:268-293`

### æ­¥éª¤ 1: åˆ›å»º StateGraph

```python
builder = StateGraph(OverallState, config_schema=Configuration)
```

### æ­¥éª¤ 2: æ·»åŠ èŠ‚ç‚¹

```python
builder.add_node("generate_query", generate_query)
builder.add_node("web_research", web_research)
builder.add_node("reflection", reflection)
builder.add_node("finalize_answer", finalize_answer)
```

### æ­¥éª¤ 3: æ·»åŠ è¾¹

```python
# å…¥å£ç‚¹: START â†’ generate_query
builder.add_edge(START, "generate_query")

# æ¡ä»¶è¾¹: generate_query â†’ continue_to_web_research â†’ web_research
builder.add_conditional_edges(
    "generate_query",
    continue_to_web_research,
    ["web_research"]
)

# æ™®é€šè¾¹: web_research â†’ reflection
builder.add_edge("web_research", "reflection")

# æ¡ä»¶è¾¹: reflection â†’ evaluate_research â†’ {web_research, finalize_answer}
builder.add_conditional_edges(
    "reflection",
    evaluate_research,
    ["web_research", "finalize_answer"]
)

# æ™®é€šè¾¹: finalize_answer â†’ END
builder.add_edge("finalize_answer", END)
```

### æ­¥éª¤ 4: ç¼–è¯‘å›¾

```python
graph = builder.compile(name="pro-search-agent")
```

---

## ğŸ”„ å®Œæ•´æ‰§è¡Œæµç¨‹ç¤ºä¾‹

### åœºæ™¯: æŸ¥è¯¢ "What are the latest trends in renewable energy?"

#### åˆå§‹çŠ¶æ€

```python
{
    "messages": [HumanMessage("What are the latest trends in renewable energy?")],
    "search_query": [],
    "web_research_result": [],
    "sources_gathered": [],
    "initial_search_query_count": 3,
    "max_research_loops": 2,
    "research_loop_count": 0
}
```

#### ç¬¬ 1 æ­¥: generate_query

**è¾“å…¥**: ç”¨æˆ·é—®é¢˜
**è¾“å‡º**:
```python
{
    "search_query": [
        "renewable energy trends 2024",
        "solar energy advancements",
        "wind energy technology"
    ]
}
```

#### ç¬¬ 2 æ­¥: continue_to_web_research

**è¾“å‡º**: 3 ä¸ªå¹¶è¡Œä»»åŠ¡
```python
[
    Send("web_research", {"search_query": "renewable energy trends 2024", "id": 0}),
    Send("web_research", {"search_query": "solar energy advancements", "id": 1}),
    Send("web_research", {"search_query": "wind energy technology", "id": 2})
]
```

#### ç¬¬ 3 æ­¥: web_research (å¹¶è¡Œæ‰§è¡Œ)

**è¾“å‡º** (ç´¯ç§¯):
```python
{
    "search_query": ["renewable energy trends 2024", "solar energy advancements", "wind energy technology"],
    "web_research_result": [
        "Summary of renewable energy trends... [1](short_url_0)",
        "Summary of solar advancements... [2](short_url_1)",
        "Summary of wind technology... [3](short_url_2)"
    ],
    "sources_gathered": [
        {"short_url": "short_url_0", "value": "https://...", "label": "..."},
        {"short_url": "short_url_1", "value": "https://...", "label": "..."},
        {"short_url": "short_url_2", "value": "https://...", "label": "..."}
    ]
}
```

#### ç¬¬ 4 æ­¥: reflection

**è¾“å…¥**: æ‰€æœ‰æœç´¢ç»“æœ
**è¾“å‡º**:
```python
{
    "is_sufficient": false,
    "knowledge_gap": "Missing cost and policy information",
    "follow_up_queries": ["renewable energy costs 2024", "energy policy 2024"],
    "research_loop_count": 1,
    "number_of_ran_queries": 3
}
```

#### ç¬¬ 5 æ­¥: evaluate_research

**åˆ¤æ–­**: `is_sufficient == false` ä¸” `research_loop_count (1) < max_loops (2)`
**è¾“å‡º**: ç»§ç»­ç ”ç©¶
```python
[
    Send("web_research", {"search_query": "renewable energy costs 2024", "id": 3}),
    Send("web_research", {"search_query": "energy policy 2024", "id": 4})
]
```

#### ç¬¬ 6 æ­¥: web_research (ç¬¬äºŒè½®,å¹¶è¡Œ)

**è¾“å‡º** (ç´¯ç§¯):
```python
{
    "web_research_result": [
        ... (ä¹‹å‰çš„ 3 ä¸ª),
        "Summary of energy costs... [4](short_url_3)",
        "Summary of policy changes... [5](short_url_4)"
    ],
    "sources_gathered": [..., ... (æ–°å¢ 2 ä¸ª)]
}
```

#### ç¬¬ 7 æ­¥: reflection (ç¬¬äºŒè½®)

**è¾“å‡º**:
```python
{
    "is_sufficient": true,
    "knowledge_gap": "",
    "follow_up_queries": [],
    "research_loop_count": 2,
    "number_of_ran_queries": 5
}
```

#### ç¬¬ 8 æ­¥: evaluate_research

**åˆ¤æ–­**: `is_sufficient == true`
**è¾“å‡º**: `"finalize_answer"`

#### ç¬¬ 9 æ­¥: finalize_answer

**è¾“å…¥**: æ‰€æœ‰ 5 ä¸ªæœç´¢ç»“æœå’Œæ¥æº
**è¾“å‡º**:
```python
{
    "messages": [
        AIMessage("Based on my research, here are the latest trends in renewable energy... [1](original_url_0) ...")
    ],
    "sources_gathered": [...]
}
```

---

## ğŸ¯ è®¾è®¡æ¨¡å¼æ€»ç»“

### 1. åæ€æ¨¡å¼ (Reflection Pattern)

```
è¡ŒåŠ¨ â†’ åæ€ â†’ å†³ç­– â†’ è¡ŒåŠ¨ (è¿­ä»£)
```

- **è¡ŒåŠ¨**: æ‰§è¡Œæœç´¢
- **åæ€**: è¯„ä¼°ç»“æœå……åˆ†æ€§
- **å†³ç­–**: ç»§ç»­æˆ–ç»“æŸ
- **è¿­ä»£**: æœ€å¤š max_loops æ¬¡

### 2. å¹¶è¡Œæ‰§è¡Œæ¨¡å¼ (Parallel Execution)

```
ä¸€ä¸ªæŸ¥è¯¢åˆ—è¡¨ â†’ å¤šä¸ªå¹¶è¡Œæœç´¢ä»»åŠ¡ â†’ ç»“æœç´¯ç§¯
```

- ä½¿ç”¨ `Send` å¯¹è±¡åˆ›å»ºå¹¶è¡Œåˆ†æ”¯
- æ¯ä¸ªä»»åŠ¡ç‹¬ç«‹æ‰§è¡Œ
- ç»“æœé€šè¿‡ `operator.add` è‡ªåŠ¨ç´¯ç§¯

### 3. æ¡ä»¶è·¯ç”±æ¨¡å¼ (Conditional Routing)

```
çŠ¶æ€è¯„ä¼° â†’ æ¡ä»¶åˆ¤æ–­ â†’ å¤šä¸ªå¯èƒ½è·¯å¾„
```

- `evaluate_research` æ ¹æ®çŠ¶æ€å†³å®šä¸‹ä¸€æ­¥
- å¯ä»¥è¿”å›å­—ç¬¦ä¸²æˆ– `Send` å¯¹è±¡åˆ—è¡¨
- å®ç°çµæ´»çš„æµç¨‹æ§åˆ¶

---

## ğŸ’¡ å®è·µå»ºè®®

### 1. åœ¨ LangGraph UI ä¸­å¯è§†åŒ–

è®¿é—® http://localhost:2024 æŸ¥çœ‹:
- å›¾ç»“æ„å¯è§†åŒ–
- èŠ‚ç‚¹æ‰§è¡Œè¿½è¸ª
- çŠ¶æ€å˜åŒ–å†å²

### 2. ä¿®æ”¹ max_research_loops

ç¼–è¾‘ `backend/.env`:
```env
MAX_RESEARCH_LOOPS=5
```

è§‚å¯Ÿè¿­ä»£æ¬¡æ•°çš„å˜åŒ–ã€‚

### 3. æ·»åŠ æ‰“å°è¯­å¥

```python
def generate_query(state: OverallState, config: RunnableConfig):
    print(f"[DEBUG] Generating queries for: {get_research_topic(state['messages'])}")
    # ... åŸæœ‰ä»£ç 
    print(f"[DEBUG] Generated queries: {result.query}")
    return {"search_query": result.query}
```

### 4. æ·»åŠ æ–°èŠ‚ç‚¹

```python
def my_custom_node(state: OverallState) -> dict:
    # è‡ªå®šä¹‰é€»è¾‘
    return {"custom_field": "value"}

# åœ¨å›¾æ„å»ºä¸­æ·»åŠ 
builder.add_node("my_custom_node", my_custom_node)
builder.add_edge("reflection", "my_custom_node")
builder.add_edge("my_custom_node", "evaluate_research")
```

---

## âœ… é˜¶æ®µ 2 æ€»ç»“

### å…³é”®æ”¶è·

1. **å›¾ç»“æ„**: LangGraph ä½¿ç”¨ StateGraph ç¼–æ’èŠ‚ç‚¹å’Œè¾¹
2. **èŠ‚ç‚¹ç±»å‹**: æ™®é€šèŠ‚ç‚¹ã€æ¡ä»¶è·¯ç”±å‡½æ•°
3. **å¹¶è¡Œæ‰§è¡Œ**: ä½¿ç”¨ `Send` å¯¹è±¡åˆ›å»ºå¹¶è¡Œä»»åŠ¡
4. **æ¡ä»¶è·¯ç”±**: æ ¹æ®çŠ¶æ€å†³å®šä¸‹ä¸€æ­¥
5. **åæ€æ¨¡å¼**: è¡ŒåŠ¨-åæ€-å†³ç­–çš„è¿­ä»£å¾ªç¯

### æ ¸å¿ƒæ¦‚å¿µå›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  START       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ generate_    â”‚â”€â”€â”€â”€â”€â”€â†’â”‚ continue_to_ â”‚
â”‚    query     â”‚       â”‚ web_research â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   web_research      â”‚
                    â”‚   (å¹¶è¡Œæ‰§è¡Œ xN)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    reflection       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  evaluate_research  â”‚
                    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                   ä¸å……åˆ†            å……åˆ†
                        â”‚              â”‚
                        â–¼              â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ web_research â”‚  â”‚ finalize_   â”‚
                â”‚  (åç»­æŸ¥è¯¢)   â”‚  â”‚   answer    â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                  â”‚   END   â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ä¸‹ä¸€æ­¥

è¿›å…¥**é˜¶æ®µ 3: æç¤ºè¯å·¥ç¨‹ä¸å·¥å…·ä½¿ç”¨**,æ·±å…¥å­¦ä¹ :
- æç¤ºè¯è®¾è®¡åŸåˆ™
- å¼•ç”¨å¤„ç†æœºåˆ¶
- å·¥å…·å‡½æ•°å®ç°

### å­¦ä¹ éªŒè¯

åœ¨è¿›å…¥ä¸‹ä¸€é˜¶æ®µå‰,ç¡®ä¿èƒ½å¤Ÿ:

- [ ] è§£é‡Šä¸ºä»€ä¹ˆéœ€è¦ `continue_to_web_research`
- [ ] ç†è§£å¹¶è¡Œæœç´¢å¦‚ä½•é€šè¿‡ `Send` å®ç°
- [ ] èƒ½ç”»å‡ºå®Œæ•´çš„çŠ¶æ€è½¬æ¢æµç¨‹å›¾
- [ ] ç†è§£æ¯ä¸ªèŠ‚ç‚¹çš„è¾“å…¥è¾“å‡ºçŠ¶æ€
- [ ] èƒ½ä¿®æ”¹å›¾ç»“æ„æ·»åŠ æ–°èŠ‚ç‚¹

---

## ğŸ“š å»¶ä¼¸é˜…è¯»

- [LangGraph Graph Concepts](https://langchain-ai.github.io/langgraph/concepts/low_level/#graphs)
- [LangGraph Send Object](https://langchain-ai.github.io/langgraph/how_to/map_reduce/)
- [Google Grounding Metadata](https://ai.google.dev/gemini-api/docs/grounding)
- [Structured Output with LLMs](https://python.langchain.com/docs/how_to/structured_output/)

---

*ä¸‹ä¸€é˜¶æ®µ: æ·±å…¥å­¦ä¹ æç¤ºè¯å·¥ç¨‹ä¸å·¥å…·ä½¿ç”¨*
