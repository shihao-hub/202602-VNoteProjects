# é˜¶æ®µ 3: æç¤ºè¯å·¥ç¨‹ä¸å·¥å…·ä½¿ç”¨

## ğŸ“š å­¦ä¹ ç›®æ ‡

- ç†è§£ç³»ç»Ÿæç¤ºè¯çš„è®¾è®¡åŸåˆ™
- æŒæ¡ç»“æ„åŒ–è¾“å‡ºçš„æç¤ºæŠ€å·§
- å­¦ä¹ å¼•ç”¨å¤„ç†å’Œ URL è§£æ
- æ·±å…¥ç†è§£å·¥å…·å‡½æ•°çš„å®ç°

---

## ğŸ¯ æç¤ºè¯å·¥ç¨‹åŸºç¡€

### ä»€ä¹ˆæ˜¯æç¤ºè¯å·¥ç¨‹?

æç¤ºè¯å·¥ç¨‹æ˜¯è®¾è®¡å’Œä¼˜åŒ– LLM è¾“å…¥,ä»¥è·å¾—é«˜è´¨é‡è¾“å‡ºçš„æŠ€æœ¯ã€‚åœ¨æœ¬é¡¹ç›®ä¸­:

- **ç»“æ„åŒ–è¾“å‡º**: ä½¿ç”¨ Pydantic BaseModel å¼ºåˆ¶è¾“å‡ºæ ¼å¼
- **ä¸Šä¸‹æ–‡æ³¨å…¥**: åŠ¨æ€æ’å…¥æ—¥æœŸã€ä¸»é¢˜ç­‰ä¿¡æ¯
- **ç¤ºä¾‹å¼•å¯¼**: æä¾›ç¤ºä¾‹ä»¥æŒ‡å¯¼æ¨¡å‹è¾“å‡º
- **çº¦æŸæ¡ä»¶**: æ˜ç¡®æŒ‡å®šè¦æ±‚å’Œé™åˆ¶

---

## ğŸ“ å››ä¸ªç³»ç»Ÿæç¤ºè¯è¯¦è§£

### 1. query_writer_instructions

**æ–‡ä»¶ä½ç½®**: `backend/src/agent/prompts.py:9-34`

#### ç›®æ ‡
ç”Ÿæˆå¤šæ ·åŒ–çš„æœç´¢æŸ¥è¯¢

#### å®Œæ•´æç¤ºè¯

```python
query_writer_instructions = """Your goal is to generate sophisticated and diverse web search queries. These queries are intended for an advanced automated web research tool capable of analyzing complex results, following links, and synthesizing information.

Instructions:
- Always prefer a single search query, only add another query if the original question requests multiple aspects or elements and one query is not enough.
- Each query should focus on one specific aspect of the original question.
- Don't produce more than {number_queries} queries.
- Queries should be diverse, if the topic is broad, generate more than 1 query.
- Don't generate multiple similar queries, 1 is enough.
- Query should ensure that the most current information is gathered. The current date is {current_date}.

Format:
- Format your response as a JSON object with ALL two of these exact keys:
   - "rationale": Brief explanation of why these queries are relevant
   - "query": A list of search queries

Example:

Topic: What revenue grew more last year apple stock or the number of people buying an iphone
```json
{{
    "rationale": "To answer this comparative growth question accurately, we need specific data points on Apple's stock performance and iPhone sales metrics. These queries target the precise financial information needed: company revenue trends, product-specific unit sales figures, and stock price movement over the same fiscal period for direct comparison.",
    "query": ["Apple total revenue growth fiscal year 2024", "iPhone unit sales growth fiscal year 2024", "Apple stock price growth fiscal year 2024"],
}}
```

Context: {research_topic}"""
```

#### è®¾è®¡åŸåˆ™

| åŸåˆ™ | å®ç° | æ•ˆæœ |
|------|------|------|
| **å•ä¸€èŒè´£** | æ¯ä¸ªæŸ¥è¯¢å…³æ³¨ä¸€ä¸ªç‰¹å®šæ–¹é¢ | æé«˜æœç´¢ç²¾åº¦ |
| **æ•°é‡æ§åˆ¶** | `Don't produce more than {number_queries}` | é¿å…è¿‡åº¦æœç´¢ |
| **å¤šæ ·æ€§** | `Queries should be diverse` | è¦†ç›–ä¸åŒè§’åº¦ |
| **å»é‡** | `Don't generate multiple similar queries` | é¿å…é‡å¤æœç´¢ |
| **æ—¶æ•ˆæ€§** | `The current date is {current_date}` | è·å–æœ€æ–°ä¿¡æ¯ |
| **ç»“æ„åŒ–è¾“å‡º** | JSON æ ¼å¼ç¤ºä¾‹ | ç¡®ä¿è¾“å‡ºå¯è§£æ |

#### æŠ€å·§åˆ†æ

**1. å˜é‡å ä½ç¬¦**
```python
{number_queries}     # åŠ¨æ€æŸ¥è¯¢æ•°é‡
{current_date}       # å½“å‰æ—¥æœŸ
{research_topic}     # ç ”ç©¶ä¸»é¢˜
```

**2. ç¤ºä¾‹å¼•å¯¼ (Few-Shot Prompting)**
```json
{
  "rationale": "...",
  "query": ["query1", "query2", "query3"]
}
```

æä¾›å…·ä½“ç¤ºä¾‹,è®©æ¨¡å‹ç†è§£æœŸæœ›çš„è¾“å‡ºæ ¼å¼ã€‚

**3. æ˜ç¡®çº¦æŸ**
```python
- Don't produce more than {number_queries} queries.
- Don't generate multiple similar queries.
```

#### ä½¿ç”¨æ–¹å¼

```python
formatted_prompt = query_writer_instructions.format(
    current_date=get_current_date(),  # "February 07, 2026"
    research_topic=get_research_topic(state["messages"]),
    number_queries=state["initial_search_query_count"],  # 3
)
```

#### è¾“å‡ºç¤ºä¾‹

**è¾“å…¥**: "What are the latest trends in renewable energy?"

**è¾“å‡º**:
```json
{
  "rationale": "These queries cover recent developments across different renewable energy sectors including overall trends, solar technology, and wind energy advancements.",
  "query": [
    "renewable energy trends 2024",
    "solar energy technology advancements 2024",
    "wind energy innovations 2024"
  ]
}
```

---

### 2. web_searcher_instructions

**æ–‡ä»¶ä½ç½®**: `backend/src/agent/prompts.py:37-48`

#### ç›®æ ‡
æ‰§è¡Œæœç´¢å¹¶æ€»ç»“ç»“æœ

#### å®Œæ•´æç¤ºè¯

```python
web_searcher_instructions = """Conduct targeted Google Searches to gather the most recent, credible information on "{research_topic}" and synthesize it into a verifiable text artifact.

Instructions:
- Query should ensure that the most current information is gathered. The current date is {current_date}.
- Conduct multiple, diverse searches to gather comprehensive information.
- Consolidate key findings while meticulously tracking the source(s) for each specific piece of information.
- The output should be a well-written summary or report based on your search findings.
- Only include the information found in the search results, don't make up any information.

Research Topic:
{research_topic}
"""
```

#### è®¾è®¡åŸåˆ™

| åŸåˆ™ | å®ç° | æ•ˆæœ |
|------|------|------|
| **æ—¶æ•ˆæ€§** | `The current date is {current_date}` | ä¼˜å…ˆæœç´¢æœ€æ–°å†…å®¹ |
| **ç»¼åˆæ€§** | `Conduct multiple, diverse searches` | å…¨é¢æ”¶é›†ä¿¡æ¯ |
| **å¯éªŒè¯æ€§** | `tracking the source(s)` | ç¡®ä¿ä¿¡æ¯å¯è¿½æº¯ |
| **çœŸå®æ€§** | `Only include the information found in the search results` | é¿å…å¹»è§‰ |
| **ç¦æ­¢ç¼–é€ ** | `don't make up any information` | ç¡®ä¿å‡†ç¡®æ€§ |

#### å…³é”®ç‚¹

è¿™ä¸ªæç¤ºè¯é…åˆ Google Search API ä½¿ç”¨:

```python
response = genai_client.models.generate_content(
    model="gemini-2.0-flash",
    contents=formatted_prompt,
    config={
        "tools": [{"google_search": {}}],  # å¯ç”¨æœç´¢
        "temperature": 0,
    },
)
```

`grounding_metadata` åŒ…å«:
- æœç´¢ç»“æœçš„æ¥æº URL
- å¼•ç”¨çš„ä½ç½®ç´¢å¼•
- ç”¨äºç”Ÿæˆå¸¦å¼•ç”¨çš„ç­”æ¡ˆ

#### è¾“å‡ºç¤ºä¾‹

```markdown
Renewable energy capacity reached new highs in 2024, with solar and wind leading the growth. Global renewable capacity increased by 25% compared to 2023, driven by declining costs and supportive policies.
```

åç»­ä¼šé€šè¿‡ `insert_citation_markers` æ’å…¥å¼•ç”¨æ ‡è®°ã€‚

---

### 3. reflection_instructions

**æ–‡ä»¶ä½ç½®**: `backend/src/agent/prompts.py:50-80`

#### ç›®æ ‡
è¯†åˆ«çŸ¥è¯†ç¼ºå£,ç”Ÿæˆåç»­æŸ¥è¯¢

#### å®Œæ•´æç¤ºè¯

```python
reflection_instructions = """You are an expert research assistant analyzing summaries about "{research_topic}".

Instructions:
- Identify knowledge gaps or areas that need deeper exploration and generate a follow-up query. (1 or multiple).
- If provided summaries are sufficient to answer the user's question, don't generate a follow-up query.
- If there is a knowledge gap, generate a follow-up query that would help expand your understanding.
- Focus on technical details, implementation specifics, or emerging trends that weren't fully covered.

Requirements:
- Ensure the follow-up query is self-contained and includes necessary context for web search.

Output Format:
- Format your response as a JSON object with these exact keys:
   - "is_sufficient": true or false
   - "knowledge_gap": Describe what information is missing or needs clarification
   - "follow_up_queries": Write a specific question to address this gap

Example:
```json
{{
    "is_sufficient": true, // or false
    "knowledge_gap": "The summary lacks information about performance metrics and benchmarks", // "" if is_sufficient is true
    "follow_up_queries": ["What are typical performance benchmarks and metrics used to evaluate [specific technology]?"] // [] if is_sufficient is true
}}
```

Reflect carefully on the Summaries to identify knowledge gaps and produce a follow-up query. Then, produce your output following this JSON format:

Summaries:
{summaries}
"""
```

#### è®¾è®¡åŸåˆ™

| åŸåˆ™ | å®ç° | æ•ˆæœ |
|------|------|------|
| **è‡ªæˆ‘è¯„ä¼°** | `is_sufficient` | åˆ¤æ–­ç ”ç©¶æ˜¯å¦å……åˆ† |
| **ç¼ºå£è¯†åˆ«** | `knowledge_gap` | æ˜ç¡®ç¼ºå¤±çš„ä¿¡æ¯ |
| **åç»­è¡ŒåŠ¨** | `follow_up_queries` | ç”Ÿæˆæ”¹è¿›æŸ¥è¯¢ |
| **è‡ªåŒ…å«** | `Ensure the follow-up query is self-contained` | æŸ¥è¯¢ç‹¬ç«‹å¯æ‰§è¡Œ |
| **èšç„¦ç»†èŠ‚** | `Focus on technical details, implementation specifics` | æ·±å…¥æŒ–æ˜ |

#### å…³é”®ç‚¹

**åŒé‡è¾“å‡ºæ¨¡å¼**:

1. **ç ”ç©¶å……åˆ†æ—¶**:
```json
{
  "is_sufficient": true,
  "knowledge_gap": "",
  "follow_up_queries": []
}
```

2. **ç ”ç©¶ä¸å……åˆ†æ—¶**:
```json
{
  "is_sufficient": false,
  "knowledge_gap": "Missing information about cost trends and policy changes",
  "follow_up_queries": [
    "renewable energy cost trends 2024",
    "energy policy changes 2024"
  ]
}
```

#### ä½¿ç”¨æ–¹å¼

```python
formatted_prompt = reflection_instructions.format(
    current_date=get_current_date(),
    research_topic=get_research_topic(state["messages"]),
    summaries="\n\n---\n\n".join(state["web_research_result"]),
)
```

å°†æ‰€æœ‰æœç´¢ç»“æœç”¨ `\n\n---\n\n` åˆ†éš”,å½¢æˆæ¸…æ™°çš„æ€»ç»“ã€‚

---

### 4. answer_instructions

**æ–‡ä»¶ä½ç½®**: `backend/src/agent/prompts.py:82-96`

#### ç›®æ ‡
ç”Ÿæˆå¸¦å¼•ç”¨çš„æœ€ç»ˆç­”æ¡ˆ

#### å®Œæ•´æç¤ºè¯

```python
answer_instructions = """Generate a high-quality answer to the user's question based on the provided summaries.

Instructions:
- The current date is {current_date}.
- You are the final step of a multi-step research process, don't mention that you are the final step.
- You have access to all the information gathered from the previous steps.
- You have access to the user's question.
- Generate a high-quality answer to the user's question based on the provided summaries and the user's question.
- Include the sources you used from the Summaries in the answer correctly, use markdown format (e.g. [apnews](https://vertexaisearch.cloud.google.com/id/1-0)). THIS IS A MUST.

User Context:
- {research_topic}

Summaries:
{summaries}"""
```

#### è®¾è®¡åŸåˆ™

| åŸåˆ™ | å®ç° | æ•ˆæœ |
|------|------|------|
| **è‡ªç„¶è¡¨è¾¾** | `don't mention that you are the final step` | æå‡ç”¨æˆ·ä½“éªŒ |
| **å®Œæ•´æ€§** | `You have access to all the information` | æ•´åˆæ‰€æœ‰ç ”ç©¶ç»“æœ |
| **å¼•ç”¨å¿…é¡»** | `THIS IS A MUST` | ç¡®ä¿å¼•ç”¨æ­£ç¡® |
| **Markdown æ ¼å¼** | `[text](url)` | å¯è¯»çš„é“¾æ¥æ ¼å¼ |

#### å…³é”®ç‚¹

**å¼•ç”¨æ ¼å¼è¦æ±‚**:
```markdown
[æ ‡é¢˜æˆ–æè¿°](https://vertexaisearch.cloud.google.com/id/{search_id}-{chunk_index})
```

ç¤ºä¾‹:
```markdown
Renewable energy capacity grew by 25% in 2024 [IEA Report](https://vertexaisearch.cloud.google.com/id/0-0).
```

#### URL æ›¿æ¢æµç¨‹

1. **åˆå§‹ç”Ÿæˆ**: ä½¿ç”¨çŸ­ URL
2. **finalize_answer**: æ›¿æ¢ä¸ºåŸå§‹ URL
3. **æœ€ç»ˆè¾“å‡º**: å¸¦å®Œæ•´å¼•ç”¨çš„ç­”æ¡ˆ

```python
# åœ¨ finalize_answer èŠ‚ç‚¹ä¸­
for source in state["sources_gathered"]:
    if source["short_url"] in result.content:
        result.content = result.content.replace(
            source["short_url"], source["value"]  # æ›¿æ¢ä¸ºåŸå§‹ URL
        )
```

---

## ğŸ› ï¸ å·¥å…·å‡½æ•°æ·±åº¦è§£æ

### 1. get_research_topic

**æ–‡ä»¶ä½ç½®**: `backend/src/agent/utils.py:5-19`

#### åŠŸèƒ½
ä»æ¶ˆæ¯å†å²ä¸­æå–ç ”ç©¶ä¸»é¢˜

#### å®ç°

```python
def get_research_topic(messages: List[AnyMessage]) -> str:
    """
    Get the research topic from the messages.
    """
    # å•è½®å¯¹è¯
    if len(messages) == 1:
        research_topic = messages[-1].content
    # å¤šè½®å¯¹è¯
    else:
        research_topic = ""
        for message in messages:
            if isinstance(message, HumanMessage):
                research_topic += f"User: {message.content}\n"
            elif isinstance(message, AIMessage):
                research_topic += f"Assistant: {message.content}\n"
    return research_topic
```

#### ä½¿ç”¨åœºæ™¯

| åœºæ™¯ | è¾“å…¥ | è¾“å‡º |
|------|------|------|
| å•è½®å¯¹è¯ | `[HumanMessage("What is AI?")]` | `"What is AI?"` |
| å¤šè½®å¯¹è¯ | `[HumanMessage("Hi"), AIMessage("Hello"), HumanMessage("What is AI?")]` | `"User: Hi\nAssistant: Hello\nUser: What is AI?\n"` |

#### å…³é”®ç‚¹

- **å•è½®å¯¹è¯**: ç›´æ¥è¿”å›æœ€åä¸€æ¡æ¶ˆæ¯
- **å¤šè½®å¯¹è¯**: æ‹¼æ¥å®Œæ•´å¯¹è¯å†å²,æä¾›ä¸Šä¸‹æ–‡

---

### 2. resolve_urls

**æ–‡ä»¶ä½ç½®**: `backend/src/agent/utils.py:22-36`

#### åŠŸèƒ½
å°†é•¿ URL è½¬æ¢ä¸ºçŸ­ URL

#### å®ç°

```python
def resolve_urls(urls_to_resolve: List[Any], id: int) -> Dict[str, str]:
    """
    Create a map of the vertex ai search urls (very long) to a short url with a unique id for each url.
    Ensures each original URL gets a consistent shortened form while maintaining uniqueness.
    """
    prefix = f"https://vertexaisearch.cloud.google.com/id/"
    urls = [site.web.uri for site in urls_to_resolve]

    # åˆ›å»ºæ˜ å°„è¡¨
    resolved_map = {}
    for idx, url in enumerate(urls):
        if url not in resolved_map:
            resolved_map[url] = f"{prefix}{id}-{idx}"

    return resolved_map
```

#### ä¸ºä»€ä¹ˆéœ€è¦çŸ­ URL?

1. **èŠ‚çœ Token**: é•¿ URL å¯èƒ½å ç”¨æ•°ç™¾å­—ç¬¦
2. **æå‡æ€§èƒ½**: å‡å°‘ä¼ è¾“å’Œå¤„ç†æ—¶é—´
3. **å¯è¯»æ€§**: çŸ­ URL æ›´æ˜“è¯»
4. **ä¸€è‡´æ€§**: åŒä¸€ä¸ª URL ä½¿ç”¨ç›¸åŒçš„çŸ­å½¢å¼

#### ç¤ºä¾‹

**è¾“å…¥**:
```python
urls_to_resolve = [
    GroundingChunk(web.uri="https://www.example.com/very/long/url/1"),
    GroundingChunk(web.uri="https://www.example.com/very/long/url/2")
]
id = 0
```

**è¾“å‡º**:
```python
{
    "https://www.example.com/very/long/url/1": "https://vertexaisearch.cloud.google.com/id/0-0",
    "https://www.example.com/very/long/url/2": "https://vertexaisearch.cloud.google.com/id/0-1"
}
```

#### URL æ ¼å¼

```
https://vertexaisearch.cloud.google.com/id/{search_id}-{chunk_index}
                                    â†‘              â†‘
                                æœç´¢ä»»åŠ¡ ID      å¼•ç”¨ç´¢å¼•
```

---

### 3. get_citations

**æ–‡ä»¶ä½ç½®**: `backend/src/agent/utils.py:78-166`

#### åŠŸèƒ½
ä» Gemini çš„ grounding_metadata æå–å¼•ç”¨

#### å®ç°åˆ†æ

```python
def get_citations(response, resolved_urls_map):
    """
    Extracts and formats citation information from a Gemini model's response.
    """
    citations = []

    # ç¡®ä¿ response å’Œå¿…è¦ç»“æ„å­˜åœ¨
    if not response or not response.candidates:
        return citations

    candidate = response.candidates[0]
    if (
        not hasattr(candidate, "grounding_metadata")
        or not candidate.grounding_metadata
        or not hasattr(candidate.grounding_metadata, "grounding_supports")
    ):
        return citations

    # éå†æ‰€æœ‰ grounding_supports
    for support in candidate.grounding_metadata.grounding_supports:
        citation = {}

        # ç¡®ä¿ segment ä¿¡æ¯å­˜åœ¨
        if not hasattr(support, "segment") or support.segment is None:
            continue

        # è·å–ç´¢å¼•
        start_index = support.segment.start_index if support.segment.start_index is not None else 0

        if support.segment.end_index is None:
            continue

        citation["start_index"] = start_index
        citation["end_index"] = support.segment.end_index
        citation["segments"] = []

        # å¤„ç† grounding_chunk_indices
        if (
            hasattr(support, "grounding_chunk_indices")
            and support.grounding_chunk_indices
        ):
            for ind in support.grounding_chunk_indices:
                try:
                    chunk = candidate.grounding_metadata.grounding_chunks[ind]
                    resolved_url = resolved_urls_map.get(chunk.web.uri, None)
                    citation["segments"].append(
                        {
                            "label": chunk.web.title.split(".")[:-1][0],
                            "short_url": resolved_url,
                            "value": chunk.web.uri,
                        }
                    )
                except (IndexError, AttributeError, NameError):
                    pass

        citations.append(citation)

    return citations
```

#### grounding_metadata ç»“æ„

```
response.candidates[0].grounding_metadata
    â”œâ”€â”€ grounding_chunks (æœç´¢ç»“æœåˆ—è¡¨)
    â”‚   â””â”€â”€ [0]
    â”‚       â””â”€â”€ web
    â”‚           â”œâ”€â”€ uri (åŸå§‹ URL)
    â”‚           â””â”€â”€ title (æ ‡é¢˜)
    â””â”€â”€ grounding_supports (å¼•ç”¨ä½ç½®åˆ—è¡¨)
        â””â”€â”€ [0]
            â””â”€â”€ segment
                â”œâ”€â”€ start_index (å¼€å§‹ä½ç½®)
                â””â”€â”€ end_index (ç»“æŸä½ç½®)
            â””â”€â”€ grounding_chunk_indices (å¼•ç”¨çš„ chunk ç´¢å¼•)
                â””â”€â”€ [0, 1]  # å¼•ç”¨äº† chunk[0] å’Œ chunk[1]
```

#### è¾“å‡ºç¤ºä¾‹

```python
[
    {
        "start_index": 50,
        "end_index": 100,
        "segments": [
            {
                "label": "IEA Report 2024",
                "short_url": "https://vertexaisearch.cloud.google.com/id/0-0",
                "value": "https://www.iea.org/reports/2024"
            }
        ]
    }
]
```

---

### 4. insert_citation_markers

**æ–‡ä»¶ä½ç½®**: `backend/src/agent/utils.py:39-75`

#### åŠŸèƒ½
åœ¨æ–‡æœ¬ä¸­æ’å…¥å¼•ç”¨æ ‡è®°

#### å®ç°

```python
def insert_citation_markers(text, citations_list):
    """
    Inserts citation markers into a text string based on start and end indices.
    """
    # ä»åå‘å‰æ’åº,é¿å…ç´¢å¼•åç§»
    sorted_citations = sorted(
        citations_list,
        key=lambda c: (c["end_index"], c["start_index"]),
        reverse=True
    )

    modified_text = text
    for citation_info in sorted_citations:
        end_idx = citation_info["end_index"]
        marker_to_insert = ""
        for segment in citation_info["segments"]:
            marker_to_insert += f" [{segment['label']}]({segment['short_url']})"

        # åœ¨ end_idx ä½ç½®æ’å…¥å¼•ç”¨æ ‡è®°
        modified_text = (
            modified_text[:end_idx] + marker_to_insert + modified_text[end_idx:]
        )

    return modified_text
```

#### å…³é”®æŠ€å·§: ä»åå‘å‰æ’å…¥

**ä¸ºä»€ä¹ˆä»åå‘å‰?**

å‡è®¾æ–‡æœ¬: `"ABCDEF"`

**ä»å‰å‘åæ’å…¥** (é”™è¯¯):
```
ä½ç½® 2 æ’å…¥ "X" â†’ "ABCXDEF"
ä½ç½® 4 æ’å…¥ "Y" â†’ "ABCXDYEF"  âŒ ä½ç½®åç§»äº†!
```

**ä»åå‘å‰æ’å…¥** (æ­£ç¡®):
```
ä½ç½® 4 æ’å…¥ "Y" â†’ "ABCDEFY"
ä½ç½® 2 æ’å…¥ "X" â†’ "ABCXDYEF"  âœ… æ­£ç¡®!
```

#### ç¤ºä¾‹

**è¾“å…¥**:
```python
text = "Renewable energy grew 25% in 2024"
citations = [
    {
        "start_index": 0,
        "end_index": 30,
        "segments": [
            {"label": "IEA", "short_url": "https://vertexaisearch.cloud.google.com/id/0-0"}
        ]
    }
]
```

**è¾“å‡º**:
```markdown
Renewable energy grew 25% in 2024 [IEA](https://vertexaisearch.cloud.google.com/id/0-0)
```

---

## ğŸ¨ å¼•ç”¨å¤„ç†å®Œæ•´æµç¨‹

### æµç¨‹å›¾

```
Google Search API
    â†“
grounding_metadata
    â”œâ”€â”€ grounding_chunks (æ¥æºä¿¡æ¯)
    â””â”€ grounding_supports (å¼•ç”¨ä½ç½®)
    â†“
resolve_urls (è½¬æ¢ä¸ºçŸ­ URL)
    â”œâ”€â”€ https://example.com/long/url/1 â†’ short_url_0
    â””â”€â”€ https://example.com/long/url/2 â†’ short_url_1
    â†“
get_citations (æå–å¼•ç”¨å¯¹è±¡)
    â””â”€â”€ [
          {
            "start_index": 50,
            "end_index": 100,
            "segments": [
              {"label": "Source 1", "short_url": "short_url_0"}
            ]
          }
        ]
    â†“
insert_citation_markers (æ’å…¥å¼•ç”¨æ ‡è®°)
    â””â”€â”€ "Text... [Source 1](short_url_0)"
    â†“
finalize_answer (æ›¿æ¢ä¸ºåŸå§‹ URL)
    â””â”€â”€ "Text... [Source 1](https://example.com/long/url/1)"
```

---

## ğŸ’¡ æç¤ºè¯è®¾è®¡æœ€ä½³å®è·µ

### 1. ç»“æ„åŒ–è¾“å‡ºæŠ€å·§

**ä½¿ç”¨ Pydantic BaseModel**:
```python
class SearchQueryList(BaseModel):
    query: List[str] = Field(description="...")
    rationale: str = Field(description="...")
```

**åœ¨æç¤ºè¯ä¸­æ˜ç¡®æ ¼å¼**:
```python
"""
Format your response as a JSON object with these exact keys:
   - "rationale": ...
   - "query": ...
"""
```

**ä½¿ç”¨ `with_structured_output`**:
```python
structured_llm = llm.with_structured_output(SearchQueryList)
result = structured_llm.invoke(prompt)
```

### 2. å˜é‡æ³¨å…¥æ¨¡å¼

```python
# ä½¿ç”¨ .format() æ³¨å…¥å˜é‡
prompt = template.format(
    current_date=get_current_date(),
    research_topic=topic,
    number_queries=3,
)
```

### 3. ç¤ºä¾‹å¼•å¯¼ (Few-Shot Prompting)

```python
"""
Example:

Topic: What is AI?
```json
{{
    "rationale": "...",
    "query": ["query1", "query2"]
}}
```
"""
```

### 4. çº¦æŸæ˜ç¡®åŒ–

```python
"""
- Don't produce more than {number_queries} queries.
- Only include the information found in the search results.
- THIS IS A MUST.
"""
```

---

## âœ… é˜¶æ®µ 3 æ€»ç»“

### å…³é”®æ”¶è·

1. **æç¤ºè¯è®¾è®¡**: å››ä¸ªç³»ç»Ÿæç¤ºè¯å„æœ‰æ˜ç¡®ç›®æ ‡
2. **ç»“æ„åŒ–è¾“å‡º**: ä½¿ç”¨ Pydantic BaseModel ç¡®ä¿æ ¼å¼æ­£ç¡®
3. **å¼•ç”¨å¤„ç†**: å®Œæ•´çš„ URL è§£æå’Œå¼•ç”¨æ’å…¥æµç¨‹
4. **å·¥å…·å‡½æ•°**: resolve_urls, get_citations, insert_citation_markers
5. **ä»åå‘å‰æ’å…¥**: é¿å…ç´¢å¼•åç§»çš„å…³é”®æŠ€å·§

### æ ¸å¿ƒæ¦‚å¿µå›¾

```
æç¤ºè¯å·¥ç¨‹
    â”œâ”€â”€ query_writer_instructions (æŸ¥è¯¢ç”Ÿæˆ)
    â”œâ”€â”€ web_searcher_instructions (æœç´¢æ€»ç»“)
    â”œâ”€â”€ reflection_instructions (åæ€åˆ†æ)
    â””â”€â”€ answer_instructions (æœ€ç»ˆç­”æ¡ˆ)

å·¥å…·å‡½æ•°
    â”œâ”€â”€ get_research_topic (æå–ä¸»é¢˜)
    â”œâ”€â”€ resolve_urls (URL ç¼©çŸ­)
    â”œâ”€â”€ get_citations (æå–å¼•ç”¨)
    â””â”€â”€ insert_citation_markers (æ’å…¥å¼•ç”¨)

å¼•ç”¨å¤„ç†æµç¨‹
    Google Search â†’ grounding_metadata
        â†’ resolve_urls â†’ get_citations
        â†’ insert_citation_markers â†’ æœ€ç»ˆç­”æ¡ˆ
```

### ä¸‹ä¸€æ­¥

è¿›å…¥**é˜¶æ®µ 4: å‰ç«¯æ¶æ„ä¸æµå¼é€šä¿¡**,æ·±å…¥å­¦ä¹ :
- React ç»„ä»¶æ¶æ„
- useStream Hook
- å®æ—¶æ´»åŠ¨æ—¶é—´çº¿

### å­¦ä¹ éªŒè¯

åœ¨è¿›å…¥ä¸‹ä¸€é˜¶æ®µå‰,ç¡®ä¿èƒ½å¤Ÿ:

- [ ] ç†è§£æ¯ä¸ªæç¤ºè¯çš„è®¾è®¡æ„å›¾
- [ ] èƒ½è§£é‡Šä¸ºä»€ä¹ˆ citations éœ€è¦ä»åå‘å‰æ’å…¥
- [ ] ç†è§£ grounding_metadata çš„ä½œç”¨
- [ ] èƒ½è®¾è®¡è‡ªå·±çš„æç¤ºè¯æ¨¡æ¿
- [ ] ç†è§£å¼•ç”¨å¤„ç†çš„å®Œæ•´æµç¨‹

---

## ğŸ“š å»¶ä¼¸é˜…è¯»

- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [Few-Shot Prompting](https://www.promptingguide.ai/techniques/fewshot)
- [Structured Output](https://python.langchain.com/docs/how_to/structured_output/)
- [Google Grounding Docs](https://ai.google.dev/gemini-api/docs/grounding)

---

*ä¸‹ä¸€é˜¶æ®µ: æ·±å…¥å­¦ä¹ å‰ç«¯æ¶æ„ä¸æµå¼é€šä¿¡*
