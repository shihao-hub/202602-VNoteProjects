# é˜¶æ®µ 6: é«˜çº§ä¸»é¢˜ä¸æ‰©å±•

## ğŸ“š å­¦ä¹ ç›®æ ‡

- æ·±å…¥ç†è§£ LangGraph é«˜çº§ç‰¹æ€§
- æŒæ¡ Agent è®¾è®¡æ¨¡å¼
- å­¦ä¹ å¦‚ä½•æ‰©å±•å’Œå®šåˆ¶é¡¹ç›®
- æ¢ç´¢æ€§èƒ½ä¼˜åŒ–å’Œç›‘æ§æ–¹æ¡ˆ

---

## ğŸ¯ LangGraph é«˜çº§æ¦‚å¿µ

### 1. StateGraph vs MessageGraph

#### StateGraph (æœ¬é¡¹ç›®ä½¿ç”¨)

```python
from langgraph.graph import StateGraph

builder = StateGraph(OverallState, config_schema=Configuration)
```

**ç‰¹ç‚¹**:
- å®Œå…¨è‡ªå®šä¹‰çš„çŠ¶æ€ç»“æ„
- ä½¿ç”¨ TypedDict å®šä¹‰çŠ¶æ€
- çµæ´»çš„çŠ¶æ€æ›´æ–°ç­–ç•¥
- é€‚åˆå¤æ‚çš„ä¸šåŠ¡é€»è¾‘

**ç¤ºä¾‹**:
```python
class OverallState(TypedDict):
    messages: Annotated[list, add_messages]
    custom_field: str
    counter: int
```

#### MessageGraph

```python
from langgraph.graph import MessageGraph

builder = MessageGraph()
```

**ç‰¹ç‚¹**:
- çŠ¶æ€ä»…ä¸ºæ¶ˆæ¯åˆ—è¡¨
- è‡ªåŠ¨è¿½åŠ æ¶ˆæ¯
- æ›´ç®€å•çš„ API
- é€‚åˆç®€å•çš„å¯¹è¯æµ

**å¯¹æ¯”**:

| ç‰¹æ€§ | StateGraph | MessageGraph |
|------|-----------|--------------|
| çŠ¶æ€ç±»å‹ | ä»»æ„ TypedDict | ä»… List[Message] |
| å¤æ‚åº¦ | é«˜ | ä½ |
| çµæ´»æ€§ | é«˜ | ä½ |
| é€‚ç”¨åœºæ™¯ | å¤æ‚ Agent | ç®€å•å¯¹è¯ |

### 2. ç¼–è¯‘é€‰é¡¹

#### checkpointer (æ£€æŸ¥ç‚¹)

```python
from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()
graph = builder.compile(checkpointer=memory)
```

**ä½œç”¨**:
- ä¿å­˜å›¾çš„ä¸­é—´çŠ¶æ€
- æ”¯æŒä¸­æ–­å’Œæ¢å¤
- å®ç°å¯¹è¯å†å²æŒä¹…åŒ–

**ä½¿ç”¨**:
```python
# è¿è¡Œæ—¶æŒ‡å®š thread_id
config = {"configurable": {"thread_id": "user-123"}}
result = graph.invoke(initial_state, config)
```

#### interrupt_before / interrupt_after

```python
graph = builder.compile(
    checkpointer=memory,
    interrupt_before=["reflection"],  # åœ¨ reflection èŠ‚ç‚¹å‰ä¸­æ–­
    interrupt_after=["web_research"]  # åœ¨ web_research èŠ‚ç‚¹åä¸­æ–­
)
```

**ç”¨é€”**:
- äººå·¥å®¡æ ¸
- è°ƒè¯•å’Œæµ‹è¯•
- æ¡ä»¶åˆ†æ”¯

### 3. æŒä¹…åŒ–å’Œæ¢å¤

#### ä¿å­˜çŠ¶æ€

```python
config = {"configurable": {"thread_id": "user-123"}}

# ç¬¬ä¸€æ¬¡è¿è¡Œ
state = {"messages": [HumanMessage("Hello")]}
graph.invoke(state, config)

# çŠ¶æ€è‡ªåŠ¨ä¿å­˜åˆ° checkpointer
```

#### æ¢å¤çŠ¶æ€

```python
# ç»§ç»­ä¹‹å‰çš„å¯¹è¯
new_state = {"messages": [HumanMessage("What's next?")]}
graph.invoke(new_state, config)  # ä½¿ç”¨ç›¸åŒçš„ thread_id
```

---

## ğŸ”„ å¹¶è¡Œæ‰§è¡Œæ¨¡å¼

### 1. Send å¯¹è±¡ (æœ¬é¡¹ç›®ä½¿ç”¨)

```python
from langgraph.types import Send

def continue_to_web_research(state):
    return [
        Send("web_research", {"search_query": q, "id": i})
        for i, q in enumerate(state["search_query"])
    ]
```

**ç‰¹ç‚¹**:
- åŠ¨æ€åˆ›å»ºå¹¶è¡Œä»»åŠ¡
- æ¯ä¸ªä»»åŠ¡ç‹¬ç«‹çŠ¶æ€
- ç»“æœè‡ªåŠ¨ç´¯ç§¯

### 2. Map-Reduce æ¨¡å¼

```python
from langgraph.graph import StateGraph

def map_node(state):
    # æ˜ å°„: å¤„ç†å•ä¸ªé¡¹ç›®
    return {"result": process_item(state["item"])}

def reduce_node(state):
    # å½’çº¦: åˆå¹¶æ‰€æœ‰ç»“æœ
    return {"final": aggregate(state["results"])}

builder = StateGraph(State)
builder.add_node("map", map_node)
builder.add_node("reduce", reduce_node)
builder.add_conditional_edges("map", map_reduce_function)
```

**åº”ç”¨åœºæ™¯**:
- æ‰¹é‡å¤„ç†
- åˆ†å¸ƒå¼è®¡ç®—
- æ•°æ®èšåˆ

### 3. åŠ¨æ€åˆ†æ”¯

```python
def router(state):
    # æ ¹æ®çŠ¶æ€åŠ¨æ€å†³å®šåˆ†æ”¯
    if state["condition"] == "A":
        return "node_a"
    elif state["condition"] == "B":
        return "node_b"
    else:
        return ["node_a", "node_b"]  # å¹¶è¡Œæ‰§è¡Œ

builder.add_conditional_edges("start", router)
```

---

## ğŸ¨ Agent è®¾è®¡æ¨¡å¼

### 1. åæ€æ¨¡å¼ (Reflection Pattern)

**æœ¬é¡¹ç›®å®ç°çš„æ ¸å¿ƒæ¨¡å¼**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       è§‚å¯Ÿç»“æœ (Research)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       åæ€åˆ†æ (Reflect)             â”‚
â”‚   - è¯†åˆ«çŸ¥è¯†ç¼ºå£                     â”‚
â”‚   - è¯„ä¼°ç ”ç©¶å……åˆ†æ€§                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       å†³ç­–è¡ŒåŠ¨ (Decide)              â”‚
â”‚   - ç»§ç»­ç ”ç©¶ OR ç”Ÿæˆç­”æ¡ˆ             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
      ç»§ç»­è¿­ä»£ â”€â”€â”˜
```

**å…³é”®è¦ç´ **:
1. **æ˜ç¡®çš„ç›®æ ‡**: å›ç­”ç”¨æˆ·é—®é¢˜
2. **è‡ªæˆ‘è¯„ä¼°**: `is_sufficient` åˆ¤æ–­
3. **è¿­ä»£ä¼˜åŒ–**: æœ€å¤š `max_loops` æ¬¡
4. **ç»ˆæ­¢æ¡ä»¶**: å……åˆ†æˆ–è¾¾åˆ°ä¸Šé™

**å®ç°è¦ç‚¹**:
```python
def reflection(state):
    result = llm.with_structured_output(Reflection).invoke(...)
    return {
        "is_sufficient": result.is_sufficient,
        "knowledge_gap": result.knowledge_gap,
        "follow_up_queries": result.follow_up_queries,
    }

def evaluate_research(state):
    if state["is_sufficient"] or state["loop_count"] >= state["max_loops"]:
        return "finalize_answer"
    else:
        return [Send("web_research", ...) for q in state["follow_up_queries"]]
```

### 2. å·¥å…·è°ƒç”¨æ¨¡å¼

#### ç»“æ„åŒ–è¾“å‡º

```python
class ToolCall(BaseModel):
    tool_name: str
    parameters: dict

llm_with_tools = llm.bind_tools([tool1, tool2])
result = llm_with_tools.invoke(query)
```

#### Function Calling

```python
class SearchQuery(BaseModel):
    query: str

structured_llm = llm.with_structured_output(SearchQuery)
result = structured_llm.invoke("Generate a search query")
```

**æœ¬é¡¹ç›®åº”ç”¨**:
- `SearchQueryList`: æŸ¥è¯¢ç”Ÿæˆ
- `Reflection`: åæ€ç»“æœ
- ä½¿ç”¨ Pydantic BaseModel ç¡®ä¿æ ¼å¼

### 3. å¤šæ™ºèƒ½ä½“åä½œ

#### å­å›¾æ¨¡å¼

```python
# å®šä¹‰å­å›¾
sub_builder = StateGraph(SubState)
sub_builder.add_node("sub_node", sub_node_function)
sub_graph = sub_builder.compile()

# æ·»åŠ åˆ°ä¸»å›¾
main_builder.add_node("sub_graph", sub_graph)
```

#### å…±äº«çŠ¶æ€

```python
class SharedState(TypedDict):
    messages: Annotated[list, add_messages]
    agent_results: Annotated[list, operator.add]

# å¤šä¸ªæ™ºèƒ½ä½“å†™å…¥åŒä¸€ä¸ªçŠ¶æ€
def agent_a(state):
    return {"agent_results": ["Agent A result"]}

def agent_b(state):
    return {"agent_results": ["Agent B result"]}
```

**é€šä¿¡æ¨¡å¼**:
- **å¹¿æ’­**: ä¸€ä¸ªæ™ºèƒ½ä½“,å¤šä¸ªæ¥æ”¶è€…
- **èšåˆ**: å¤šä¸ªæ™ºèƒ½ä½“,ä¸€ä¸ªæ±‡æ€»
- **æ¥åŠ›**: æ™ºèƒ½ä½“ä¾æ¬¡å¤„ç†

---

## ğŸš€ é¡¹ç›®æ‰©å±•æ–¹å‘

### 1. åŠŸèƒ½æ‰©å±•

#### æ·»åŠ æ–°çš„æœç´¢æº

```python
# åœ¨ tools_and_schemas.py ä¸­æ·»åŠ 
from arxiv import ArxivAPI

def arxiv_search(state: WebSearchState) -> OverallState:
    """ä½¿ç”¨ ArXiv API æœç´¢å­¦æœ¯è®ºæ–‡"""
    client = ArxivAPI()
    results = client.search(state["search_query"], max_results=5)

    return {
        "sources_gathered": [
            {"label": r.title, "value": r.url, "short_url": shorten_url(r.url)}
            for r in results
        ],
        "web_research_result": [summarize_papers(results)],
    }

# åœ¨ graph.py ä¸­æ·»åŠ èŠ‚ç‚¹
builder.add_node("arxiv_search", arxiv_search)
```

#### å®ç°å¯¹è¯å†å²ç®¡ç†

```python
from langgraph.checkpoint.postgres import PostgresSaver

# ä½¿ç”¨ PostgreSQL æŒä¹…åŒ–
connection = "postgres://user:pass@localhost/db"
checkpointer = PostgresSaver.from_conn_string(connection)

graph = builder.compile(checkpointer=checkpointer)

# è¿è¡Œæ—¶æŒ‡å®š thread_id
config = {"configurable": {"thread_id": f"user-{user_id}"}}
result = graph.invoke(state, config)
```

#### æ·»åŠ ç”¨æˆ·è®¤è¯

```python
# backend/src/agent/auth.py
from fastapi import HTTPException, Depends
from fastapi.security import HTTPBearer

security = HTTPBearer()

async def verify_token(token: str = Depends(security)):
    """éªŒè¯ JWT token"""
    try:
        payload = decode_jwt(token.credentials)
        return payload["user_id"]
    except JWTError:
        raise HTTPException(status_code=401, detail="Invalid token")

# åœ¨ app.py ä¸­ä½¿ç”¨
@app.post("/runs")
async def create_run(
    request: Request,
    user_id: str = Depends(verify_token)
):
    # å¤„ç†è¯·æ±‚
    pass
```

### 2. æ€§èƒ½ä¼˜åŒ–

#### ç¼“å­˜æœç´¢ç»“æœ

```python
from functools import lru_cache
import hashlib

@lru_cache(maxsize=100)
def cached_search(query: str):
    """ç¼“å­˜æœç´¢ç»“æœ"""
    return google_search_api(query)

def web_research(state: WebSearchState):
    # ä½¿ç”¨ç¼“å­˜
    cache_key = hashlib.md5(state["search_query"].encode()).hexdigest()
    results = cached_search(cache_key)
    # ...
```

#### æ‰¹é‡æŸ¥è¯¢å¤„ç†

```python
from concurrent.futures import ThreadPoolExecutor

def parallel_web_search(queries: list[str]):
    """å¹¶è¡Œæ‰§è¡Œå¤šä¸ªæœç´¢"""
    with ThreadPoolExecutor(max_workers=5) as executor:
        results = list(executor.map(google_search_api, queries))
    return results
```

#### å¼‚æ­¥èŠ‚ç‚¹æ‰§è¡Œ

```python
import asyncio

async def async_web_research(state: WebSearchState):
    """å¼‚æ­¥ç½‘ç»œæœç´¢"""
    results = await asyncio.gather(
        google_search_async(q1),
        google_search_async(q2),
        google_search_async(q3),
    )
    return {"web_research_result": results}
```

### 3. ç›‘æ§å’Œè°ƒè¯•

#### LangSmith é›†æˆ

```python
import os

os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = "your_langsmith_key"

# è‡ªåŠ¨è¿½è¸ªæ‰€æœ‰ LLM è°ƒç”¨å’Œå›¾æ‰§è¡Œ
```

**åŠŸèƒ½**:
- å¯è§†åŒ–æ‰§è¡Œæµç¨‹
- æ€§èƒ½åˆ†æ
- æˆæœ¬è¿½è¸ª
- è°ƒè¯•å·¥å…·

#### è‡ªå®šä¹‰æ—¥å¿—è®°å½•

```python
import logging

logger = logging.getLogger(__name__)

def logged_node(state):
    logger.info(f"Node input: {state}")
    result = process(state)
    logger.info(f"Node output: {result}")
    return result

# ä½¿ç”¨è£…é¥°å™¨
def log_node(func):
    def wrapper(state):
        logger.debug(f"Entering {func.__name__}")
        result = func(state)
        logger.debug(f"Exiting {func.__name__}")
        return result
    return wrapper

@log_node
def generate_query(state):
    # ...
    pass
```

#### æ€§èƒ½æŒ‡æ ‡æ”¶é›†

```python
import time
from prometheus_client import Counter, Histogram

# å®šä¹‰æŒ‡æ ‡
query_counter = Counter('queries_total', 'Total queries')
search_duration = Histogram('search_duration_seconds', 'Search duration')

def web_research(state):
    start = time.time()
    result = google_search_api(state["search_query"])
    duration = time.time() - start

    query_counter.inc()
    search_duration.observe(duration)

    return {"web_research_result": [result]}
```

---

## ğŸ› ï¸ å®è·µé¡¹ç›®å»ºè®®

### ç®€å•: æ·»åŠ å¤©æ°”æŸ¥è¯¢åŠŸèƒ½

```python
# 1. å®šä¹‰å·¥å…·
class WeatherQuery(BaseModel):
    location: str

# 2. åˆ›å»ºèŠ‚ç‚¹
def weather_search(state: OverallState):
    llm = ChatOpenAI(...)
    structured_llm = llm.with_structured_output(WeatherQuery)

    # æå–ä½ç½®
    query = structured_llm.invoke(get_research_topic(state["messages"]))

    # è°ƒç”¨å¤©æ°” API
    weather = get_weather(query.location)

    return {
        "web_research_result": [f"Weather in {query.location}: {weather}"]
    }

# 3. æ·»åŠ åˆ°å›¾
builder.add_node("weather_search", weather_search)
builder.add_conditional_edges("generate_query", route_to_weather_or_search)
```

### ä¸­ç­‰: å®ç°å¤šè¯­è¨€æ”¯æŒ

```python
# 1. æ·»åŠ è¯­è¨€æ£€æµ‹
def detect_language(messages):
    from langdetect import detect
    return detect(messages[-1].content)

# 2. åœ¨é…ç½®ä¸­æ·»åŠ è¯­è¨€å­—æ®µ
class Configuration(BaseModel):
    language: str = Field(default="en")

# 3. ä¿®æ”¹æç¤ºè¯ä»¥æ”¯æŒå¤šè¯­è¨€
query_writer_instructions = """
Generate search queries in {language} language.
...
"""

# 4. åœ¨èŠ‚ç‚¹ä¸­ä½¿ç”¨
def generate_query(state, config):
    configurable = Configuration.from_runnable_config(config)
    language = detect_language(state["messages"])

    formatted_prompt = query_writer_instructions.format(
        language=language,
        # ...
    )
    # ...
```

### å¤æ‚: æ„å»ºä»£ç åˆ†æ Agent

```python
# 1. å®šä¹‰ä»£ç åˆ†æçŠ¶æ€
class CodeAnalysisState(TypedDict):
    repository_url: str
    code_files: Annotated[list, operator.add]
    analysis_results: Annotated[list, operator.add]
    vulnerabilities: list

# 2. åˆ›å»ºèŠ‚ç‚¹
def clone_repo(state):
    """å…‹éš† GitHub ä»“åº“"""
    repo_url = state["repository_url"]
    local_path = git_clone(repo_url)
    return {"local_path": local_path}

def analyze_code(state):
    """åˆ†æä»£ç æ–‡ä»¶"""
    files = list_code_files(state["local_path"])
    results = [analyze_file(f) for f in files]
    return {"analysis_results": results}

def detect_vulnerabilities(state):
    """æ£€æµ‹å®‰å…¨æ¼æ´"""
    code = state["code_files"]
    vulnerabilities = security_scan(code)
    return {"vulnerabilities": vulnerabilities}

# 3. æ„å»ºå›¾
builder = StateGraph(CodeAnalysisState)
builder.add_node("clone", clone_repo)
builder.add_node("analyze", analyze_code)
builder.add_node("scan", detect_vulnerabilities)
builder.add_edge(START, "clone")
builder.add_edge("clone", "analyze")
builder.add_edge("analyze", "scan")
builder.add_edge("scan", END)
```

### é«˜çº§: åˆ›å»ºå¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿ

```python
# 1. å®šä¹‰ä¸åŒè§’è‰²çš„æ™ºèƒ½ä½“
class ResearcherState(TypedDict):
    topic: str
    findings: list

class WriterState(TypedDict):
    research: list
    draft: str

class EditorState(TypedDict):
    draft: str
    feedback: str

# 2. åˆ›å»ºå­å›¾
researcher = create_researcher_graph()
writer = create_writer_graph()
editor = create_editor_graph()

# 3. ç»„åˆåˆ°ä¸»å›¾
main_builder = StateGraph(OverallState)
main_builder.add_node("researcher", researcher)
main_builder.add_node("writer", writer)
main_builder.add_node("editor", editor)

# 4. å®šä¹‰åä½œæµç¨‹
main_builder.add_edge(START, "researcher")
main_builder.add_edge("researcher", "writer")
main_builder.add_conditional_edges("writer", review_draft)
main_builder.add_edge("editor", END)
```

---

## ğŸ“ å­¦ä¹ æˆæœéªŒè¯

å®Œæˆæ‰€æœ‰é˜¶æ®µå,ä½ åº”è¯¥èƒ½å¤Ÿ:

### 1. ç†è§£å±‚é¢

- âœ… è§£é‡Š LangGraph çš„å·¥ä½œåŸç†
- âœ… ç†è§£ AI Agent çš„åæ€æ¨¡å¼
- âœ… æŒæ¡çŠ¶æ€ç®¡ç†å’Œæµå¼é€šä¿¡
- âœ… ç†è§£å¹¶è¡Œæ‰§è¡Œå’Œæ¡ä»¶è·¯ç”±
- âœ… æŒæ¡å‰åç«¯é€šä¿¡æœºåˆ¶

### 2. å®è·µå±‚é¢

- âœ… ç‹¬ç«‹è®¾è®¡å’Œå®ç°æ–°çš„ Agent èŠ‚ç‚¹
- âœ… å®šåˆ¶æç¤ºè¯æé«˜è¾“å‡ºè´¨é‡
- âœ… æ‰©å±•å‰ç«¯åŠŸèƒ½
- âœ… æ·»åŠ æ–°çš„æœç´¢æº
- âœ… å®ç°ç¼“å­˜å’Œä¼˜åŒ–

### 3. æ¶æ„å±‚é¢

- âœ… è®¾è®¡å¤æ‚çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ
- âœ… ä¼˜åŒ–æ€§èƒ½å’Œæˆæœ¬
- âœ… éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
- âœ… å®ç°ç›‘æ§å’Œè°ƒè¯•
- âœ… é›†æˆå¤–éƒ¨ API

---

## ğŸ“š æ¨èèµ„æº

### å®˜æ–¹æ–‡æ¡£

1. **LangGraph æ–‡æ¡£**: https://langchain-ai.github.io/langgraph/
2. **LangChain æ–‡æ¡£**: https://python.langchain.com/
3. **Google Gemini API**: https://ai.google.dev/gemini-api/docs
4. **FastAPI æ–‡æ¡£**: https://fastapi.tiangolo.com/

### é«˜çº§ä¸»é¢˜

1. **Prompt Engineering Guide**: https://www.promptingguide.ai/
2. **Designing AI Agents**: https://arxiv.org/abs/2308.11432
3. **ReAct Pattern**: https://arxiv.org/abs/2210.03629
4. **Reflection in LLMs**: https://arxiv.org/abs/2303.11366

### å®è·µé¡¹ç›®

1. **LangGraph Templates**: https://github.com/langchain-ai/langgraph/tree/main/examples
2. **Agent Prototypes**: https://github.com/e2b-dev/awesome-ai-agents
3. **Multi-Agent Systems**: https://github.com/OpenBMB/AgentVerse

---

## âœ… å®Œæ•´å­¦ä¹ è·¯å¾„æ€»ç»“

```
é˜¶æ®µ 0: ç¯å¢ƒå‡†å¤‡ä¸é¡¹ç›®æ¦‚è§ˆ
    â”œâ”€ ç†è§£é¡¹ç›®æ¶æ„
    â”œâ”€ æ­å»ºå¼€å‘ç¯å¢ƒ
    â””â”€ è¿è¡Œé¡¹ç›®

é˜¶æ®µ 1: åç«¯æ ¸å¿ƒ - çŠ¶æ€ç®¡ç†
    â”œâ”€ OverallState, ReflectionState ç­‰
    â”œâ”€ Annotated æœºåˆ¶
    â””â”€ Configuration é…ç½®

é˜¶æ®µ 2: LangGraph å›¾ç»“æ„
    â”œâ”€ èŠ‚ç‚¹: generate_query, web_research, reflection
    â”œâ”€ è¾¹: æ™®é€šè¾¹ã€æ¡ä»¶è¾¹
    â”œâ”€ å¹¶è¡Œæ‰§è¡Œ: Send å¯¹è±¡
    â””â”€ å›¾æ„å»ºæµç¨‹

é˜¶æ®µ 3: æç¤ºè¯å·¥ç¨‹ä¸å·¥å…·ä½¿ç”¨
    â”œâ”€ å››ä¸ªç³»ç»Ÿæç¤ºè¯
    â”œâ”€ å¼•ç”¨å¤„ç†æœºåˆ¶
    â””â”€ å·¥å…·å‡½æ•°å®ç°

é˜¶æ®µ 4: å‰ç«¯æ¶æ„ä¸æµå¼é€šä¿¡
    â”œâ”€ useStream Hook
    â”œâ”€ äº‹ä»¶æµå¤„ç†
    â”œâ”€ æ´»åŠ¨æ—¶é—´çº¿
    â””â”€ Markdown æ¸²æŸ“

é˜¶æ®µ 5: å‰åç«¯é€šä¿¡ä¸éƒ¨ç½²
    â”œâ”€ FastAPI é›†æˆ
    â”œâ”€ Docker éƒ¨ç½²
    â”œâ”€ Redis (Pub-Sub)
    â””â”€ PostgreSQL (çŠ¶æ€æŒä¹…åŒ–)

é˜¶æ®µ 6: é«˜çº§ä¸»é¢˜ä¸æ‰©å±•
    â”œâ”€ LangGraph é«˜çº§ç‰¹æ€§
    â”œâ”€ Agent è®¾è®¡æ¨¡å¼
    â”œâ”€ é¡¹ç›®æ‰©å±•æ–¹å‘
    â””â”€ æ€§èƒ½ä¼˜åŒ–å’Œç›‘æ§
```

---

## ğŸ‰ æ­å–œå®Œæˆå­¦ä¹ è®¡åˆ’!

ä½ å·²ç»ç³»ç»ŸåŒ–åœ°æŒæ¡äº†è¿™ä¸ª Gemini Fullstack LangGraph é¡¹ç›®çš„æ¯ä¸€ä¸ªç»†èŠ‚ã€‚ç°åœ¨ä½ å¯ä»¥:

1. **ç†è§£** AI Agent çš„è®¾è®¡å’Œå·¥ä½œåŸç†
2. **æ„å»º** è‡ªå·±çš„ LangGraph åº”ç”¨
3. **æ‰©å±•** é¡¹ç›®åŠŸèƒ½ä»¥æ»¡è¶³ç‰¹å®šéœ€æ±‚
4. **éƒ¨ç½²** åˆ°ç”Ÿäº§ç¯å¢ƒå¹¶ä¼˜åŒ–æ€§èƒ½

**ä¸‹ä¸€æ­¥å»ºè®®**:
- é€‰æ‹©ä¸€ä¸ªå®è·µé¡¹ç›®å¹¶å®ç°
- åŠ å…¥ LangChain ç¤¾åŒºå¹¶åˆ†äº«ä½ çš„ä½œå“
- æ¢ç´¢æ›´å¤æ‚çš„ Agent æ¶æ„
- å…³æ³¨æœ€æ–°çš„ AI Agent ç ”ç©¶è¿›å±•

ç¥ä½ å­¦ä¹ æ„‰å¿«! ğŸš€

---

## ğŸ“ å­¦ä¹ æ£€æŸ¥æ¸…å•

### åŸºç¡€çŸ¥è¯†
- [ ] Python ç±»å‹ç³»ç»Ÿ (TypedDict, Annotated)
- [ ] React Hooks (useState, useEffect, useCallback)
- [ ] TypeScript åŸºç¡€
- [ ] HTTP å’Œ WebSocket

### AI/ML åŸºç¡€
- [ ] LLM åŸºæœ¬æ¦‚å¿µ
- [ ] Prompt Engineering
- [ ] ç»“æ„åŒ–è¾“å‡º
- [ ] Token è®¡ç®—å’Œæˆæœ¬

### æ¡†æ¶ç‰¹å®š
- [ ] LangGraph æ ¸å¿ƒæ¦‚å¿µ
- [ ] LangChain åŸºç¡€
- [ ] FastAPI åŸºç¡€
- [ ] Vite æ„å»ºç³»ç»Ÿ

### å®è·µæŠ€èƒ½
- [ ] èƒ½ç‹¬ç«‹è¿è¡Œé¡¹ç›®
- [ ] èƒ½ä¿®æ”¹å’Œæ‰©å±•åŠŸèƒ½
- [ ] èƒ½éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
- [ ] èƒ½è°ƒè¯•å’Œä¼˜åŒ–æ€§èƒ½

---

**æ–‡æ¡£å®Œæˆæ—¥æœŸ**: 2026-02-07
**é¡¹ç›®ç‰ˆæœ¬**: gemini-fullstack-langgraph-quickstart
**å­¦ä¹ è·¯å¾„**: å…­é˜¶æ®µç³»ç»ŸåŒ–å­¦ä¹ è®¡åˆ’

---

*æ­å–œä½ å®Œæˆäº†å®Œæ•´çš„å­¦ä¹ ä¹‹æ—…! ğŸ“*
