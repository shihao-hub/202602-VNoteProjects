# Kiro Spec Coding - FastAPI 项目思路

## 1. Routers 层架构

routers 的实现函数中的具体实现是交给 Service 层的（通过 fastapi 依赖注入的方式注入 service 实例），也就是说 routers 层主要负责异常处理等

## 2. Service 层架构

service 类中，会初始化 Repository 层实例，service 通过这个实例与数据库打交道

但是 service 层也会通过 数据库会话 直接和数据库打交道

> 提到 session 这个数据库会话，sqlalchemy 好像一直传递下去，避免反复获取 session

## 3. 测试代码特点

**测试框架：** tests 是基于 pytest 的

Kiro Spec Coding 生成的 tests 代码几乎都是下面的类型：

| 测试类型 | 测试内容 | 是否使用真实服务 |
|---------|---------|----------------|
| 模型测试 | SQLAlchemy/Pydantic 模型字段验证 | ❌ 否 |
| 纯函数测试 | 编码/解码、延迟计算、异常转换 | ❌ 否 |
| 验证测试 | Pydantic schema 验证逻辑 | ❌ 否 |

**不涉及真实服务。**

> 其实这是必然的，按照我的初步体会，spec 模式前期生成的代码更多的是整体跑起来没问题、依赖库或者格式没问题、懒加载直到主动调用 API 去触发才会发现问题等。

> 那么这也不可能生成真正的调用真实服务的测试代码呀！

**测试价值：**

我发现，tests 的基础测试靠 AI 还是有价值的，比如 request 请求的格式，未来变更后，这边也能检测到！只不过没那么严格，划分一下优先级即可。

**举例：**

```
FAILED tests/test_email_schemas.py::TestBatchRequestValidation::test_valid_batch_request_passes
FAILED tests/test_quota_status.py::TestQuotaStatusRealtime::test_quota_status_reflects_config_defaults
...
12 failed, 82 passed in 38.03s
```

这些失败能及时发现 schema 变更导致的问题（如 SESConfig、CreateBatchRequest 的验证错误）。

---

## 4. Claude Code 的价值

Claude Code + GLM 可以充当讲解项目源码的作用。毕竟网页版的问答 AI 不知道项目的上下文。

---

## 5. Kiro 工作流程与困惑

**工作流程：**
```
outline.md (含相关链接)
    ↓
反复沟通 (spec coding 模式)
    ↓
requirements.md → design.md → tasks.md
    ↓
生成可运行的项目代码
```

**实际体验：**
- 开发出来的项目基本上都是可运行的
- 顶多数据库表可能会和业务没那么相关（但这是 requirements.md 和 design.md 中的内容）

**困惑：**
requirements.md 等文件变更会导致 design.md、tasks.md 变化吗？如果变化了，已经生成的代码怎么办？最终岂不是乱七八糟的了？

---

**实战困惑 (2026-01-27)：**

我基于一个设计好的接口文档，让 kiro 一口气生成了全部代码，结果由于 backend 会与 outreach 通信，实际上二者存在共享数据表的可能，在这种情况下，我需要改动数据模型，这触动了 kiro 生成的代码的根本，kiro 总共 10 个任务，模型为第 1 个任务建立，改动模型导致我已经不知道用什么提示词继续了。

**我的理解：**

1. requirements.md 和 design.md 在 tasks.md 生成前就确定，tasks.md 生成后，这两个文件我实在不知道怎么改动，就我目前的看法是，最好别改动...

2. 在不熟悉 kiro 的情况下，尽量还是小步快走，比如邮箱服务，先让他实现发邮件服务再继续吧

3. spec coding 似乎要求设计文档在未来不再进行大变更的情况下才更合适？不然我真不知道该如何是好了

4. 代码修改还是必须要进行 git 提交才行，便于未来回滚。但是 git 提交只是折中的方案，似乎 claudia 这个项目可以做到对话回滚代码也回滚

---

## 6. 开发实践与思考

**代码质量：**
kiro 生成的代码确实不错

**当前开发阶段：**
详细细节还需要和前端联调或者需求对齐的时候进行。当前开发没有明确的需求，所以想要自己好好思考，目前还没有掌握这种能力。

**自测阶段目标：**
基本上保证 postman 手动测试能跑通端点，能满足初步预期即可，比如：
- 邮件成功发送
- 聚合数据成功返回等

---

## 7. 未来进阶方向

- 独立进行需求调研、需求分析、需求设计、需求拆分、需求实现
- 能应对变化，比如数据库表字段变化、数据前后兼容等
- ...

---

## 8. Kiro 实现模式观察

**文件修改策略：**
kiro 似乎会在实现一个独立的需求过程中，很少改动原有文件（主要修改的是 `__init__.py` 文件），而是创建新文件。

**Web 服务开发顺序：**
对于一个 web 服务，kiro 在 tasks.md 的末尾才会开始定义 API 端点。在这之前更多的是：
- 实现逻辑（不测试）
- 测试生成的代码是否有逻辑错误
- 测试 schema、dataclass 等结构是否正确

---

## 9. 实战案例：邮件服务开发 (2026-01-26)

**开发流程：**

1. **准备阶段：**
   - 通过 Claude Code 和与同事沟通
   - 最终定版一个 API 接口文档

2. **Kiro Spec 模式输入：**
   ```
   #Influencer Submission Email的API接口文档.md 这是接口文档，请基于接口文档的内容和以下内容，进行需求分析、需求设计、开发等。
   ```

3. **业务场景补充：**
   - 基于用户侧和达人的沟通历史记录，需要维护 thread_id/session_id 会话
   - 针对每个会话能获取到历史所有发送和回复记录
   - 支持和同一个达人创建新的会话
   - 会话和沟通的邮件是 1:n 场景
   - 需要解耦邮箱业务表（区分发送箱|草稿箱|垃圾箱、区分场景化自定义邮箱标签、区分 AI 标签）和邮箱原始数据表
   - 需要基于 KOL 的邮件回复，后续会扩展邮箱的应用场景和标签
   - 需要考虑提报单：提报单红人：沟通邮件 = 1：N：N 的关系

4. **自动化流程：**
   - requirements.md > design.md > tasks.md 一路不参与，直接生成

5. **代码生成：**
   - 手动点击 tasks.md 完成代码

---

**任务分析（重点）：**

tasks.md 总共 11 个任务：
- 任务 10：编写单元测试
- 任务 11：确保所有测试通过
- 真正的代码运行任务：前 9 个任务

暂不考虑测试相关代码，只谈前 9 个任务的实践观察。

**文件创建模式：**

这 9 个任务，实践后发现，全程几乎没有在原有代码文件中添加内容，全是创建的新文件（git: changes 5, unversioned files 34）。

**优点：**
1. 独立，代码不耦合
2. 用户开始调试阶段清晰又明了

**可能的缺点（个人看法）：**
1. 不会去复用项目现有逻辑
2. 可能并没有怎么理解当前项目

**调试建议：**

后续调试阶段，可以直接打开 kiro 的每一个任务对话，查看文件变更。

---

**我的评价：**

直接放开所有权限（读写等，没有删除），让 kiro 一口气写完所有代码（暂时排除测试相关代码），接着程序员的任务就是阅读源代码和调通项目即可。

**这样的开发流程：**

```
前期：靠 AI 和自己思考调研完成初步文档
  ↓
中期：让 AI 根据这个文档生成项目源代码
  ↓
后期：程序员阅读源代码、微调、跑通整个代码
  ↓
初步测试
  ↓
和前端联调完善
```
